{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Installs and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "!pip install matplotlib\n",
    "!pip install plotly\n",
    "#install all packages needed from this notebook\n",
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install sklearn\n",
    "!pip install librosa\n",
    "!pip install IPython\n",
    "%pip install imblearn\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_kj_path = \"../data/raw/annotations_koti_janmani.txt\"\n",
    "annotations_vnk_path = \"../data/raw/annotations_vanajaksha_ninni_kore.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_seconds(t):\n",
    "    return (t.hour * 60 * 60) + (t.minute * 60) + t.second + (t.microsecond / 1000000)\n",
    "\n",
    "def load_annotations_file(path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load annotations from a file.\n",
    "\n",
    "    :param path: Path to the file containing the annotations.\n",
    "    :return: A pandas DataFrame containing the annotations.\n",
    "    \"\"\"\n",
    "    # Read the annotations file\n",
    "    annotations = pd.read_csv(path, sep='\\t', header=None)\n",
    "\n",
    "    # Add column names\n",
    "    annotations.columns = [\"level\", \"\", \"start\", \"end\", \"duration\", \"label\"]\n",
    "    del annotations[\"\"]\n",
    "\n",
    "    # Convert to seconds\n",
    "    annotations[\"start\"] = pd.to_datetime(annotations[\"start\"])\n",
    "    annotations[\"end\"] = pd.to_datetime(annotations[\"end\"])\n",
    "    annotations[\"start\"] = annotations[\"start\"].apply(to_seconds)\n",
    "    annotations[\"end\"] = annotations[\"end\"].apply(to_seconds)\n",
    "    annotations[\"duration\"] = pd.to_timedelta(annotations['duration']).dt.total_seconds()\n",
    "\n",
    "    annotations.reset_index(inplace=True)\n",
    "\n",
    "    return annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_kj = load_annotations_file(annotations_kj_path)\n",
    "annotations_vnk = load_annotations_file(annotations_vnk_path)\n",
    "\n",
    "#annotations_vnk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_kj_usancara = annotations_kj[annotations_kj[\"level\"] == \"underlying_sancara\"]\n",
    "annotations_vnk_usancara = annotations_vnk[annotations_vnk[\"level\"] == \"root_sancara\"]\n",
    "\n",
    "#annotations_vnk_usancara"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_kj_path = \"../data/raw/Koti Janmani/Koti Janmani.multitrack-vocal.mp3\"\n",
    "audio_vnk_path = \"../data/raw/Vanajaksha Ninne Kori/Vanajaksha Ninne Kori_vocal.mp3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio_file(path: str, sampling_rate: int) -> tuple:\n",
    "    audio_time_series, sr = librosa.load(path, sr=sampling_rate)\n",
    "    return audio_time_series, sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_kj, sr_kj = load_audio_file(audio_kj_path, 44100)\n",
    "audio_vnk, sr_vnk = load_audio_file(audio_vnk_path, 44100)\n",
    "\n",
    "#Audio(data=audio_vnk, rate=sr_vnk)\n",
    "Audio(data=audio_kj, rate=sr_kj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Extract pitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passar la ref a una constant (per fer el canvi de Hz a cents)\n",
    "tonic_path_kj = \"../data/raw/Koti Janmani/Koti Janmani.ctonic.txt\"\n",
    "tonic_path_vnk = \"../data/raw/Vanajaksha Ninne Kori/Vanajaksha Ninne Kori.ctonic.txt\"\n",
    "\n",
    "with open(tonic_path_kj, \"r\") as f:\n",
    "    ctonic_ref_kj = float(f.readline().strip())\n",
    "\n",
    "with open(tonic_path_vnk, \"r\") as f:\n",
    "    ctonic_ref_vnk = float(f.readline().strip())\n",
    "\n",
    "ctonic_ref_vnk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import savgol_filter\n",
    "\n",
    "def pitch_to_cents(pitch: float, ref: float):\n",
    "    if pitch == 0:\n",
    "        return None\n",
    "    else:\n",
    "        return 1200 * math.log(pitch/ref, 2)\n",
    "\n",
    "def interpolate_and_smooth_pitch(pitch, ts):\n",
    "    pitch = pd.Series(pitch)\n",
    "    pitch[pitch <= 0] = np.nan\n",
    "    pitch_interpolated = pitch.interpolate(method=\"linear\")\n",
    "    pitch_smoothed = savgol_filter(pitch_interpolated, window_length=50, polyorder=2)\n",
    "    #pitch_smoothed = savgol_filter(pitch_interpolated, window_length=int((250*0.001)/ts), polyorder=3)\n",
    "    return pitch_smoothed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract pitch from pitch file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_path_kj = \"../data/raw/Koti Janmani/Koti_Janmani.melodia.pitch.txt\"\n",
    "pitch_path_vnk = \"../data/raw/Vanajaksha Ninne Kori/Vanajaksha Ninne Kori.melodia.pitch.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pitch_file(path: str):\n",
    "    \"\"\"\n",
    "    Load a pitch file from a given path.\n",
    "\n",
    "    :param path: Path to the pitch file.\n",
    "    :return: pitch_file, time, pitch, timestep\n",
    "    \"\"\"\n",
    "    pitch_file = pd.read_csv(path, sep=\"\\t\", header=None)\n",
    "    pitch_file.columns = [\"time\", \"pitch\"]\n",
    "\n",
    "    time = pitch_file[\"time\"].values\n",
    "    pitch = pitch_file[\"pitch\"].values\n",
    "    timestep = time[1] - time[0]\n",
    "\n",
    "    return pitch_file, time, pitch, timestep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_file_kj, time_kj, pitch_kj, timestep_kj = load_pitch_file(pitch_path_kj)\n",
    "pitch_file_vnk, time_vnk, pitch_vnk, timestep_vnk = load_pitch_file(pitch_path_vnk)\n",
    "\n",
    "# Replace non-positive values with NaN, interpolate and smooth\n",
    "pitch_kj_smoothed = interpolate_and_smooth_pitch(pitch_kj, timestep_kj)\n",
    "pitch_vnk_smoothed = interpolate_and_smooth_pitch(pitch_vnk, timestep_vnk)\n",
    "\n",
    "# Convert pitch to cents\n",
    "pitch_cents_kj = np.array([pitch_to_cents(p, ctonic_ref_kj) for p in pitch_kj_smoothed])\n",
    "pitch_cents_vnk = np.array([pitch_to_cents(p, ctonic_ref_vnk) for p in pitch_vnk_smoothed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pitch_cents_kj[10000:10020]\n",
    "pitch_cents_vnk[10000:10020]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pitch was extracted using melodia and saved into the files: \"Koti Janmani.melodia.pitch.txt\" , \"Vanajaksha Ninne Kori.melodia.pitch.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Time Domain Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from librosa.feature import rms\n",
    "from librosa.feature import zero_crossing_rate as zcr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_features_kj_df = annotations_kj_usancara.copy()\n",
    "time_features_vnk_df = annotations_vnk_usancara.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 Root Mean Square Energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rms(audio: np.ndarray, sample_start: float, sample_end: float, sr: int) -> float:\n",
    "    sample = audio[round(sample_start * sr):round(sample_end * sr)]\n",
    "    return np.mean(rms(y=sample)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: a stands for annotation\n",
    "time_features_kj_df['rmse'] = time_features_kj_df.apply(\n",
    "    lambda a: compute_rms(audio_kj, a['start'], a['end'], sr_kj), axis=1\n",
    ")\n",
    "time_features_vnk_df['rmse'] = time_features_vnk_df.apply(\n",
    "    lambda a: compute_rms(audio_vnk, a['start'], a['end'], sr_vnk), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 Zero Crossing Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_zcr(audio: np.ndarray, sample_start: float, sample_end: float, sr: int) -> float:\n",
    "    sample = audio[round(sample_start * sr):round(sample_end * sr)]\n",
    "    return np.mean(zcr(y=sample)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_features_kj_df['zcr'] = time_features_kj_df.apply(\n",
    "    lambda a: compute_zcr(audio_kj, a['start'], a['end'], sr_kj), axis=1\n",
    ")\n",
    "time_features_vnk_df['zcr'] = time_features_vnk_df.apply(\n",
    "    lambda a: compute_zcr(audio_vnk, a['start'], a['end'], sr_vnk), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time Domain Features DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#time_features_kj_df\n",
    "#time_features_vnk_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Frequency Domain Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from librosa.feature import spectral_centroid as scentroid\n",
    "from librosa.feature import spectral_bandwidth as sbandwidth\n",
    "from librosa.feature import spectral_rolloff as srolloff\n",
    "from librosa.feature import mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_features_kj_df = annotations_kj_usancara.copy()\n",
    "frequency_features_vnk_df = annotations_vnk_usancara.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 Spectral Centroid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each frame of a magnitude spectrogram is normalized and treated as a distribution over frequency bins, from which the mean (centroid) is extracted per frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_scentroid(audio: np.ndarray, sample_start: float, sample_end: float, sr: int) -> float:\n",
    "    sample = audio[round(sample_start * sr):round(sample_end * sr)]\n",
    "    return np.mean(scentroid(y=sample, sr=sr)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_features_kj_df['spectral_centroid'] = frequency_features_kj_df.apply(\n",
    "    lambda a: compute_scentroid(audio_kj, a['start'], a['end'], sr_kj), axis=1\n",
    ")\n",
    "frequency_features_vnk_df['spectral_centroid'] = frequency_features_vnk_df.apply(\n",
    "    lambda a: compute_scentroid(audio_vnk, a['start'], a['end'], sr_vnk), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 Spectral Bandwidth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sbandwidth(audio: np.ndarray, sample_start: float, sample_end: float, sr: int) -> float:\n",
    "    sample = audio[round(sample_start * sr):round(sample_end * sr)]\n",
    "    return np.mean(sbandwidth(y=sample, sr=sr)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_features_kj_df['spectral_bandwidth'] = frequency_features_kj_df.apply(\n",
    "    lambda a: compute_sbandwidth(audio_kj, a['start'], a['end'], sr_kj), axis=1\n",
    ")\n",
    "frequency_features_vnk_df['spectral_bandwidth'] = frequency_features_vnk_df.apply(\n",
    "    lambda a: compute_sbandwidth(audio_vnk, a['start'], a['end'], sr_vnk), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.3 Spectral Rolloff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The roll-off frequency is defined for each frame as the center frequency for a spectrogram bin such that at least roll_percent (0.85 by default) of the energy of the spectrum in this frame is contained in this bin and the bins below. This can be used to, e.g., approximate the maximum (or minimum) frequency by setting roll_percent to a value close to 1 (or 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_srolloff(audio: np.ndarray, sample_start: float, sample_end: float, sr: int) -> float:\n",
    "    sample = audio[round(sample_start * sr):round(sample_end * sr)]\n",
    "    return np.mean(srolloff(y=sample, sr=sr)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_features_kj_df['spectral_rolloff'] = frequency_features_kj_df.apply(\n",
    "    lambda a: compute_srolloff(audio_kj, a['start'], a['end'], sr_kj), axis=1\n",
    ")\n",
    "frequency_features_vnk_df['spectral_rolloff'] = frequency_features_vnk_df.apply(\n",
    "    lambda a: compute_srolloff(audio_vnk, a['start'], a['end'], sr_vnk), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.4 Mel Frequency Cepstral Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_kj_df = annotations_kj_usancara.copy()\n",
    "mfcc_vnk_df = annotations_vnk_usancara.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mfcc(audio: np.ndarray, sample_start: float, sample_end: float, sr: int) -> np.ndarray:\n",
    "    sample = audio[round(sample_start * sr):round(sample_end * sr)]\n",
    "    return np.mean(mfcc(y=sample, sr=sr, n_mfcc=6), axis=1)\n",
    "\n",
    "mfcc_cols = [f'mfcc_{i+1}' for i in range(6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_kj_df[mfcc_cols] = mfcc_kj_df.apply(\n",
    "    lambda a: compute_mfcc(audio_kj, a['start'], a['end'], sr_kj), axis=1\n",
    ").apply(pd.Series)\n",
    "mfcc_vnk_df[mfcc_cols] = mfcc_vnk_df.apply(\n",
    "    lambda a: compute_mfcc(audio_vnk, a['start'], a['end'], sr_vnk), axis=1\n",
    ").apply(pd.Series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequency Domain Features DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#frequency_features_kj_df\n",
    "#frequency_features_vnk_df\n",
    "mfcc_kj_df\n",
    "#mfcc_vnk_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Pitch Curve Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_features_kj_df = annotations_kj_usancara.copy()\n",
    "pitch_features_vnk_df = annotations_vnk_usancara.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1 Mean pitch, Min/Max and Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_min_max_pitch(cents: np.ndarray, tstep: float, sample_start: float, sample_end: float):\n",
    "    #sample_time = time[round(sample_start/tstep):round(sample_end/tstep)]\n",
    "    sample_cents = cents[round(sample_start/tstep):round(sample_end/tstep)]\n",
    "    return np.mean(sample_cents), min(sample_cents), max(sample_cents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_features_kj_df[['mean_pitch', 'min_pitch', 'max_pitch']] = pitch_features_kj_df.apply(\n",
    "    lambda a: get_mean_min_max_pitch(pitch_cents_kj, timestep_kj, a['start'], a['end']), axis=1\n",
    ").apply(pd.Series)\n",
    "pitch_features_vnk_df[['mean_pitch', 'min_pitch', 'max_pitch']] = pitch_features_vnk_df.apply(\n",
    "    lambda a: get_mean_min_max_pitch(pitch_cents_vnk, timestep_vnk, a['start'], a['end']), axis=1\n",
    ").apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Range\n",
    "pitch_features_kj_df['pitch_range'] = pitch_features_kj_df['max_pitch'] - pitch_features_kj_df['min_pitch']\n",
    "pitch_features_vnk_df['pitch_range'] = pitch_features_vnk_df['max_pitch'] - pitch_features_vnk_df['min_pitch']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2 Number of Change Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import find_peaks\n",
    "\n",
    "def compute_number_of_change_points(cents: np.ndarray, prominence: int, tstep: float, sample_start: float, sample_end: float) -> int:\n",
    "    #sample_time = time[round(sample_start/tstep):round(sample_end/tstep)]\n",
    "    sample_cents = cents[round(sample_start/tstep):round(sample_end/tstep)]\n",
    "\n",
    "    peaks, _ = find_peaks(sample_cents, prominence=prominence) # Use PROMINENCE to get only significant change points (> 70 cents is significant)\n",
    "    valleys, _ = find_peaks(-sample_cents, prominence=prominence)\n",
    "\n",
    "    num_change_points = len(peaks) + len(valleys)\n",
    "    return num_change_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prominence = 70 #cents\n",
    "\n",
    "pitch_features_kj_df['num_change_points'] = pitch_features_kj_df.apply(\n",
    "    lambda a: compute_number_of_change_points(pitch_cents_kj, prominence, timestep_kj, a['start'], a['end']), axis=1\n",
    ")\n",
    "pitch_features_vnk_df['num_change_points'] = pitch_features_vnk_df.apply(\n",
    "    lambda a: compute_number_of_change_points(pitch_cents_vnk, prominence, timestep_vnk, a['start'], a['end']), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.3 Number of Change Points per second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_number_of_change_points_per_second(cents: np.ndarray, prominence: int, tstep: float, sample_start: float, sample_end: float) -> float:\n",
    "    num_change_points = compute_number_of_change_points(cents, prominence, tstep, sample_start, sample_end)\n",
    "    return num_change_points / (sample_end - sample_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_features_kj_df['num_change_points_per_second'] = pitch_features_kj_df.apply(\n",
    "    lambda a: compute_number_of_change_points_per_second(pitch_cents_kj, prominence, timestep_kj, a['start'], a['end']), axis=1\n",
    ")\n",
    "pitch_features_vnk_df['num_change_points_per_second'] = pitch_features_vnk_df.apply(\n",
    "    lambda a: compute_number_of_change_points_per_second(pitch_cents_vnk, prominence, timestep_vnk, a['start'], a['end']), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pitch Curve Features DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pitch_features_kj_df\n",
    "#pitch_features_vnk_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Create DataFrame with the Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a features dataframe for each song\n",
    "cols_to_drop = [\"index\", \"level\", \"start\", \"end\", \"duration\", \"label\"]\n",
    "features_kj_df = pd.concat([annotations_kj_usancara, \n",
    "                        time_features_kj_df.drop(columns=cols_to_drop),\n",
    "                        frequency_features_kj_df.drop(columns=cols_to_drop),\n",
    "                        mfcc_kj_df.drop(columns=cols_to_drop),\n",
    "                        pitch_features_kj_df.drop(columns=cols_to_drop)],\n",
    "axis=1)\n",
    "features_vnk_df = pd.concat([annotations_vnk_usancara,\n",
    "                        time_features_vnk_df.drop(columns=cols_to_drop),\n",
    "                        frequency_features_vnk_df.drop(columns=cols_to_drop),\n",
    "                        mfcc_vnk_df.drop(columns=cols_to_drop),\n",
    "                        pitch_features_vnk_df.drop(columns=cols_to_drop)],\n",
    "axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge both dataframes\n",
    "features_df = pd.concat([features_kj_df, features_vnk_df], axis=0)\n",
    "features_df['level'] = features_df['level'].apply(lambda y: y.replace('root','underlying'))\n",
    "\n",
    "#features_df[130:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "def normalize_dataframe(df: pd.DataFrame, features) -> pd.DataFrame:\n",
    "    for f in features:\n",
    "        if f != 'num_change_points' and f != 'num_change_points_per_second':\n",
    "            df[f] = (df[f] - df[f].mean()) / df[f].std()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = ['rmse', 'zcr', \n",
    "            'spectral_centroid', 'spectral_bandwidth', 'spectral_rolloff',\n",
    "            'mfcc_1', 'mfcc_2', 'mfcc_3', 'mfcc_4', 'mfcc_5', 'mfcc_6',\n",
    "            'mean_pitch', 'min_pitch', 'max_pitch', 'pitch_range', 'num_change_points', 'num_change_points_per_second']\n",
    "features_pitch = ['mean_pitch', 'min_pitch', 'max_pitch', 'pitch_range', 'num_change_points', 'num_change_points_per_second']\n",
    "\n",
    "norm_features_df = normalize_dataframe(features_df, all_features)\n",
    "norm_features_df[130:150]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Comparing NNS (no subsequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = norm_features_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nns = df[df['label'] == 'nns']\n",
    "df_nns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_multiple_patterns_pitch(pitch_cents_list, time_list, tstep_list, sample_start_list, sample_end_list):\n",
    "    \"\"\"\n",
    "    Compara múltiples patrones de pitch en un solo gráfico.\n",
    "\n",
    "    pitch_cents_list: Lista de arrays de pitch en cents.\n",
    "    time_list: Lista de arrays de tiempo correspondientes.\n",
    "    tstep_list: Lista de pasos de tiempo para cada conjunto de datos.\n",
    "    sample_start_list: Lista de tiempos de inicio para los fragmentos a comparar.\n",
    "    sample_end_list: Lista de tiempos de fin para los fragmentos a comparar.\n",
    "    \"\"\"\n",
    "    colors = ['blue', 'red', 'green', 'purple', 'orange', 'cyan', 'magenta', 'yellow', 'black', 'grey']\n",
    "    num_patterns = len(pitch_cents_list)\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    for i in range(num_patterns):\n",
    "        pitch_cents = pitch_cents_list[i]\n",
    "        time = time_list[i]\n",
    "        tstep = tstep_list[i]\n",
    "        sample_start = sample_start_list[i]\n",
    "        sample_end = sample_end_list[i]\n",
    "        \n",
    "        sample_time = time[round(sample_start/tstep):round(sample_end/tstep)]\n",
    "        sample_time = sample_time - sample_start\n",
    "        sample_cents = pitch_cents[round(sample_start/tstep):round(sample_end/tstep)]\n",
    "        \n",
    "        plt.plot(sample_time, sample_cents, label=f'Pattern {i+1}', color=colors[i % len(colors)])\n",
    "    \n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Pitch (cents)')\n",
    "    plt.legend()\n",
    "    plt.title('Comparison of Pitch Patterns')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_cents_list = [pitch_cents_kj, pitch_cents_kj, pitch_cents_kj, pitch_cents_kj, pitch_cents_kj]\n",
    "time_list = [time_kj, time_kj, time_kj, time_kj, time_kj]\n",
    "tstep_list = [timestep_kj, timestep_kj, timestep_kj, timestep_kj, timestep_kj]\n",
    "\n",
    "sample_start_list = [df_nns['start'].iloc[i] for i in range(0, 5)]\n",
    "sample_end_list = [df_nns['end'].iloc[i] for i in range(0, 5)]\n",
    "\n",
    "compare_multiple_patterns_pitch(pitch_cents_list, time_list, tstep_list, sample_start_list, sample_end_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modelling to predict NNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = norm_features_df.copy()\n",
    "label = 'nns'\n",
    "\n",
    "# Get IS_NNS\n",
    "filtered_df = df[df['label'] == label]\n",
    "dummies_df = pd.get_dummies(filtered_df['label'], prefix='is')\n",
    "result_df = df.join(dummies_df).fillna(False)\n",
    "\n",
    "# Get CONTAINS_NNS\n",
    "result_df['contains_nns'] = result_df['label'].apply(lambda y: label in y)\n",
    "# result_df['contains_nns'].value_counts() -- 61 values\n",
    "\n",
    "# Convert the labels to a binary format\n",
    "cols_to_convert = [f'is_{label}', f'contains_{label}']\n",
    "result_df[cols_to_convert] = result_df[cols_to_convert].astype(int)\n",
    "result_df[100:120]\n",
    "\n",
    "#save the dataframe to csv\n",
    "#result_df.to_csv('../data/processed/containsss.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURES and TARGETS\n",
    "\n",
    "all_features = ['rmse', 'zcr', \n",
    "            'spectral_centroid', 'spectral_bandwidth', 'spectral_rolloff',\n",
    "            'mfcc_1', 'mfcc_2', 'mfcc_3', 'mfcc_4', 'mfcc_5', 'mfcc_6', \n",
    "            'mean_pitch', 'min_pitch', 'max_pitch', 'pitch_range', 'num_change_points', 'num_change_points_per_second']\n",
    "\n",
    "targets = [f'is_{label}', f'contains_{label}']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Get Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting is_nns\n",
    "X_is_nns = result_df[all_features].values\n",
    "y_is_nns = result_df[targets[0]].values\n",
    "X_train_is_nns, X_test_is_nns, y_train_is_nns, y_test_is_nns = train_test_split(X_is_nns, y_is_nns, test_size=0.3, random_state=42, stratify=y_is_nns)\n",
    "\n",
    "# Splitting contains_nns\n",
    "X_contains_nns = result_df[all_features].values\n",
    "y_contains_nns = result_df[targets[1]].values\n",
    "X_train_contains_nns, X_test_contains_nns, y_train_contains_nns, y_test_contains_nns = train_test_split(X_contains_nns, y_contains_nns, test_size=0.3, random_state=42, stratify=y_contains_nns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importances using GradientBoosting\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# IS_NNS\n",
    "features_is_nns = []\n",
    "clf = GradientBoostingClassifier(random_state=42)\n",
    "clf.fit(X_train_is_nns, y_train_is_nns)\n",
    "print(\"Feature importances for IS_NNS using Gradient Boosting ordered by most relevance\\n\")\n",
    "for feature, importance in sorted(zip(all_features, clf.feature_importances_), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{feature.ljust(23)} \\t\\t\\t{importance*100:.2f} %\")\n",
    "    if importance > 0.02:\n",
    "        features_is_nns.append(feature)\n",
    "\n",
    "# CONTAINS_NNS\n",
    "features_contains_nns = []\n",
    "clf = GradientBoostingClassifier(random_state=42)\n",
    "clf.fit(X_train_contains_nns, y_train_contains_nns)\n",
    "print(\"\\nFeature importances for CONTAINS_NNS using Gradient Boosting ordered by most relevance\\n\")\n",
    "for feature, importance in sorted(zip(all_features, clf.feature_importances_), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{feature.ljust(23)} \\t\\t\\t{importance*100:.2f} %\")\n",
    "    if importance > 0.02:\n",
    "        features_contains_nns.append(feature)\n",
    "\n",
    "#features_is_nns\n",
    "#features_contains_nns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Random Predictions to set a baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Info about metrics:  https://www.evidentlyai.com/classification-metrics/accuracy-precision-recall\n",
    "from sklearn.metrics import accuracy_score # Accuracy = (Correct predictions / Total predictions) * 100 === (TP + TN) / (TP + TN + FP + FN)\n",
    "from sklearn.metrics import precision_score # Precision = (TP) / (TP + FP) the % of correct positive predictions over the total PREDICTED positives\n",
    "from sklearn.metrics import recall_score # Recall = (TP) / (TP + FN) the % of correct positive predictions over the total ACTUAL positives\n",
    "\n",
    "from sklearn.metrics import f1_score # F1 = 2 * (Precision * Recall) / (Precision + Recall) the harmonic mean of precision and recall\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute random predictions\n",
    "\n",
    "for t in targets:\n",
    "    if t == targets[0]: # IS_NNS\n",
    "        # SPLITTING\n",
    "        X = result_df[all_features].values # TODO: Change to features_is_nns\n",
    "        y = result_df[t].values\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=None)\n",
    "\n",
    "        # RANDOM PREDICTION\n",
    "        is_accuracies = []\n",
    "        is_precisions = []\n",
    "        is_recalls = []\n",
    "        is_f1s = []\n",
    "        unique_classes = np.unique(y_test)\n",
    "        for _ in range(100):\n",
    "            random_predictions = np.random.choice(unique_classes, len(y_test))\n",
    "            is_accuracies.append(accuracy_score(y_true=y_test, y_pred=random_predictions))\n",
    "            is_precisions.append(precision_score(y_true=y_test, y_pred=random_predictions))\n",
    "            is_recalls.append(recall_score(y_true=y_test, y_pred=random_predictions))\n",
    "            is_f1s.append(f1_score(y_true=y_test, y_pred=random_predictions))\n",
    "\n",
    "        # EVALUATION\n",
    "        is_random_accuracy = np.mean(is_accuracies)\n",
    "        is_random_precision = np.mean(is_precisions)\n",
    "        is_random_recall = np.mean(is_recalls)\n",
    "        is_random_f1 = np.mean(is_f1s)\n",
    "\n",
    "        print(f'RANDOM IS_NNS: Test ACCURACY for target {t}: {is_random_accuracy}')\n",
    "        print(f'RANDOM IS_NNS: Test PRECISION for target {t}: {is_random_precision}')\n",
    "        print(f'RANDOM IS_NNS: Test RECALL for target {t}: {is_random_recall}')\n",
    "        print(f'RANDOM IS_NNS: Test F1 for target {t}: {is_random_f1}')\n",
    "        print(\"-----------------------------------\")\n",
    "    elif t == targets[1]: # CONTAINS_NNS\n",
    "        # SPLITTING\n",
    "        X = result_df[all_features].values # TODO: Change to features_contains_nns\n",
    "        y = result_df[t].values\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=None)\n",
    "\n",
    "        # RANDOM PREDICTION\n",
    "        contains_accuracies = []\n",
    "        contains_precisions = []\n",
    "        contains_recalls = []\n",
    "        contains_f1s = []\n",
    "        unique_classes = np.unique(y_test)\n",
    "        for _ in range(100):\n",
    "            random_predictions = np.random.choice(unique_classes, len(y_test))\n",
    "            contains_accuracies.append(accuracy_score(y_true=y_test, y_pred=random_predictions))\n",
    "            contains_precisions.append(precision_score(y_true=y_test, y_pred=random_predictions))\n",
    "            contains_recalls.append(recall_score(y_true=y_test, y_pred=random_predictions))\n",
    "            contains_f1s.append(f1_score(y_true=y_test, y_pred=random_predictions))\n",
    "\n",
    "        # EVALUATION\n",
    "        contains_random_accuracy = np.mean(contains_accuracies)\n",
    "        contains_random_precision = np.mean(contains_precisions)\n",
    "        contains_random_recall = np.mean(contains_recalls)\n",
    "        contains_random_f1 = np.mean(contains_f1s)\n",
    "\n",
    "        print(f'RANDOM: Test ACCURACY for target {t}: {contains_random_accuracy}')\n",
    "        print(f'RANDOM: Test PRECISION for target {t}: {contains_random_precision}')\n",
    "        print(f'RANDOM: Test RECALL for target {t}: {contains_random_recall}')\n",
    "        print(f'RANDOM: Test F1 for target {t}: {contains_random_f1}')\n",
    "        print(\"-----------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Train and evaluate a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.1 Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# TRAINING with GradientBoostingClassifier and GridSearchCV (only) and EVALUATING\n",
    "params = {\n",
    "    'n_estimators':[20,60,80],\n",
    "    'learning_rate': [0.075, 0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "    'max_depth':[8,10],\n",
    "}\n",
    "results_table = []\n",
    "\n",
    "for t in targets:\n",
    "    if t == targets[0]: # IS_NNS\n",
    "        # SPLITTING\n",
    "        X = result_df[features_is_nns].values # TODO: Change to features_is_nns\n",
    "        y = result_df[t].values\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=None)\n",
    "\n",
    "        # TRAINING\n",
    "        clf = GradientBoostingClassifier(random_state=42)\n",
    "        gs = GridSearchCV(clf, param_grid=params, scoring='f1', cv=4)\n",
    "        gs.fit(X_train, y_train)\n",
    "\n",
    "        # PREDICTION\n",
    "        best = gs.best_estimator_\n",
    "        y_pred = best.predict(X_test)\n",
    "\n",
    "        # EVALUATION\n",
    "        is_f1_gbc = f1_score(y_true=y_test, y_pred=y_pred)\n",
    "        is_accuracy_gbc = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "        is_precision_gbc = precision_score(y_true=y_test, y_pred=y_pred)\n",
    "        is_recall_gbc = recall_score(y_true=y_test, y_pred=y_pred)\n",
    "\n",
    "        results_table.append({\n",
    "            'Class': t,\n",
    "            'Accuracy': is_accuracy_gbc,\n",
    "            'Precision': is_precision_gbc,\n",
    "            'Recall': is_recall_gbc,\n",
    "            'F1-Score': is_f1_gbc,\n",
    "            'CV Score': gs.best_score_\n",
    "        })\n",
    "        print(f'Best parameters for target {t}: {gs.best_params_}')\n",
    "        print(f'Test ACCURACY for target {t}: {is_accuracy_gbc}')\n",
    "        print(f'Test PRECISION for target {t}: {is_precision_gbc}')\n",
    "        print(f'Test RECALL for target {t}: {is_recall_gbc}')\n",
    "        print(f'Test F1 for target {t}: {is_f1_gbc}')\n",
    "        print(f'CV Score for target {t}: {gs.best_score_}')\n",
    "\n",
    "        print(\"Confusion matrix:\")\n",
    "        cm = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "        cm_display = ConfusionMatrixDisplay(confusion_matrix=cm) # [TP, FP], [TN, FN]\n",
    "        cm_display.plot()\n",
    "        plt.show()\n",
    "        print(\"-----------------------------------\")\n",
    "    elif t == targets[1]: # CONTAINS_NNS\n",
    "        # SPLITTING\n",
    "        X = result_df[features_contains_nns].values # TODO: Change to features_contains_nns\n",
    "        y = result_df[t].values\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=None)\n",
    "\n",
    "        # TRAINING\n",
    "        clf = GradientBoostingClassifier(random_state=42)\n",
    "        gs = GridSearchCV(clf, param_grid=params, scoring='f1', cv=4)\n",
    "        gs.fit(X_train, y_train)\n",
    "\n",
    "        # PREDICTION\n",
    "        best = gs.best_estimator_\n",
    "        y_pred = best.predict(X_test)\n",
    "\n",
    "        # EVALUATION\n",
    "        contains_f1_gbc = f1_score(y_true=y_test, y_pred=y_pred)\n",
    "        contains_accuracy_gbc = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "        contains_precision_gbc = precision_score(y_true=y_test, y_pred=y_pred)\n",
    "        contains_recall_gbc = recall_score(y_true=y_test, y_pred=y_pred)\n",
    "\n",
    "        results_table.append({\n",
    "            'Class': t,\n",
    "            'Accuracy': contains_accuracy_gbc,\n",
    "            'Precision': contains_precision_gbc,\n",
    "            'Recall': contains_recall_gbc,\n",
    "            'F1-Score': contains_f1_gbc,\n",
    "            'CV Score': gs.best_score_\n",
    "        })\n",
    "        print(f'Best parameters for target {t}: {gs.best_params_}')\n",
    "        print(f'Test ACCURACY for target {t}: {contains_accuracy_gbc}')\n",
    "        print(f'Test PRECISION for target {t}: {contains_precision_gbc}')\n",
    "        print(f'Test RECALL for target {t}: {contains_recall_gbc}')\n",
    "        print(f'Test F1 for target {t}: {contains_f1_gbc}')\n",
    "        print(f'CV Score for target {t}: {gs.best_score_}')\n",
    "\n",
    "        print(\"Confusion matrix:\")\n",
    "        cm = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "        cm_display = ConfusionMatrixDisplay(confusion_matrix=cm) # [TP, FP], [TN, FN]\n",
    "        cm_display.plot()\n",
    "        plt.show()\n",
    "        print(\"-----------------------------------\")\n",
    "\n",
    "# Print the results table\n",
    "print(\"Analysis\\n\")\n",
    "for result in results_table:\n",
    "    print(\"Class: {}\\nPrecision: {:.2f}\\nRecall: {:.2f}\\nF1-Score: {:.2f}\\nCV Score: {:.2f}\\n\".format(result['Class'], result['Precision'], result['Recall'], result['F1-Score'], result['CV Score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.2 Gradient Boosting with KFolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training with GradientBoostingClassifier using GridSearchCV with StratifiedKFold cross-validation.\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "params = {\n",
    "    'n_estimators':[20,60,80],\n",
    "    'learning_rate': [0.075, 0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "    'max_depth':[8,10],\n",
    "}\n",
    "test_size = 0.3\n",
    "best_results = {}\n",
    "results_table = []\n",
    "\n",
    "print ('Training with GradientBoostingClassifier using GridSearchCV with StratifiedKFold cross-validation.')\n",
    "for t in targets:\n",
    "    if t == targets[0]: # IS_NNS\n",
    "        # SPLITTING\n",
    "        X = result_df[features_is_nns].values # TODO: Change to features_is_nns\n",
    "        y = result_df[t].values\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42, stratify=y)\n",
    "\n",
    "        # TRAINING\n",
    "        clf = GradientBoostingClassifier(random_state=42) #aixi sempre es pot reproduir el mateix model\n",
    "        skf = StratifiedKFold(n_splits=5)\n",
    "        gs = GridSearchCV(clf, param_grid=params, scoring='f1', cv=skf)\n",
    "        gs.fit(X_train, y_train)\n",
    "\n",
    "        # PREDICTION\n",
    "        best = gs.best_estimator_\n",
    "        y_pred = best.predict(X_test)\n",
    "        print('_')\n",
    "\n",
    "        # EVALUATION\n",
    "        is_f1_gbc_kf = f1_score(y_true=y_test, y_pred=y_pred)\n",
    "        is_accuracy_gbc_kf = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "        is_precision_gbc_kf = precision_score(y_true=y_test, y_pred=y_pred)\n",
    "        is_recall_gbc_kf = recall_score(y_true=y_test, y_pred=y_pred)\n",
    "        is_support_gbc_kf = len(y_test)\n",
    "        # Analysis is subjective and should be written based on the metrics\n",
    "        if is_precision_gbc_kf == 1.0:\n",
    "            analysis = \"The model achieves perfect precision, indicating high confidence in identifying {}. However, it misses about {} of actual {} segments (false negatives).\".format(t, 1-is_recall_gbc_kf, t)\n",
    "        else:\n",
    "            analysis = \"The model shows good balance between precision and recall for detecting {}. There's room for improvement in capturing more instances without compromising precision.\".format(t)\n",
    "        results_table.append({\n",
    "            'Class': t,\n",
    "            'Accuracy': is_accuracy_gbc_kf,\n",
    "            'Precision': is_precision_gbc_kf,\n",
    "            'Recall': is_recall_gbc_kf,\n",
    "            'F1-Score': is_f1_gbc_kf,\n",
    "            'Support': is_support_gbc_kf,\n",
    "            'Analysis': analysis,\n",
    "            'cv_score': gs.best_score_\n",
    "        })\n",
    "        print(f'Best parameters for target {t}: {gs.best_params_}')\n",
    "        print(f'Test ACCURACY for target {t}: {is_accuracy_gbc_kf}')\n",
    "        print(f'Test PRECISION for target {t}: {is_precision_gbc_kf}')\n",
    "        print(f'Test RECALL for target {t}: {is_recall_gbc_kf}')\n",
    "        print(f'Test F1 for target {t}: {is_f1_gbc_kf}')\n",
    "        print(f'Cross-validation score for target {t}: {gs.best_score_}')\n",
    "        print(\"Confusion matrix:\")\n",
    "        cm = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "        cm_display = ConfusionMatrixDisplay(confusion_matrix=cm) # [TP, FP], [TN, FN]\n",
    "        cm_display.plot()\n",
    "        plt.show()\n",
    "        print(\"-----------------------------------\")\n",
    "    elif t == targets[1]: # CONTAINS_NNS\n",
    "        # SPLITTING\n",
    "        X = result_df[features_contains_nns].values # TODO: Change to features_contains_nns\n",
    "        y = result_df[t].values\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42, stratify=y)\n",
    "\n",
    "        # TRAINING\n",
    "        clf = GradientBoostingClassifier(random_state=42) #aixi sempre es pot reproduir el mateix model\n",
    "        skf = StratifiedKFold(n_splits=5)\n",
    "        gs = GridSearchCV(clf, param_grid=params, scoring='f1', cv=skf)\n",
    "        gs.fit(X_train, y_train)\n",
    "\n",
    "        # PREDICTION\n",
    "        best = gs.best_estimator_\n",
    "        y_pred = best.predict(X_test)\n",
    "        print('_')\n",
    "\n",
    "        # EVALUATION\n",
    "        contains_f1_gbc_kf = f1_score(y_true=y_test, y_pred=y_pred)\n",
    "        contains_accuracy_gbc_kf = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "        contains_precision_gbc_kf = precision_score(y_true=y_test, y_pred=y_pred)\n",
    "        contains_recall_gbc_kf = recall_score(y_true=y_test, y_pred=y_pred)\n",
    "        contains_support_gbc_kf = len(y_test)\n",
    "        # Analysis is subjective and should be written based on the metrics\n",
    "        if contains_precision_gbc_kf == 1.0:\n",
    "            analysis = \"The model achieves perfect precision, indicating high confidence in identifying {}. However, it misses about {} of actual {} segments (false negatives).\".format(t, 1-contains_recall_gbc_kf, t)\n",
    "        else:\n",
    "            analysis = \"The model shows good balance between precision and recall for detecting {}. There's room for improvement in capturing more instances without compromising precision.\".format(t)\n",
    "        results_table.append({\n",
    "            'Class': t,\n",
    "            'Accuracy': contains_accuracy_gbc_kf,\n",
    "            'Precision': contains_precision_gbc_kf,\n",
    "            'Recall': contains_recall_gbc_kf,\n",
    "            'F1-Score': contains_f1_gbc_kf,\n",
    "            'Support': contains_support_gbc_kf,\n",
    "            'Analysis': analysis,\n",
    "            'cv_score': gs.best_score_\n",
    "        })\n",
    "        print(f'Best parameters for target {t}: {gs.best_params_}')\n",
    "        print(f'Test ACCURACY for target {t}: {contains_accuracy_gbc_kf}')\n",
    "        print(f'Test PRECISION for target {t}: {contains_precision_gbc_kf}')\n",
    "        print(f'Test RECALL for target {t}: {contains_recall_gbc_kf}')\n",
    "        print(f'Test F1 for target {t}: {contains_f1_gbc_kf}')\n",
    "        print(f'Cross-validation score for target {t}: {gs.best_score_}')\n",
    "        print(\"Confusion matrix:\")\n",
    "        cm = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "        cm_display = ConfusionMatrixDisplay(confusion_matrix=cm) # [TP, FP], [TN, FN]\n",
    "        cm_display.plot()\n",
    "        plt.show()\n",
    "        print(\"-----------------------------------\")\n",
    "\n",
    "# Print the results table\n",
    "print(\"Analysis\\n\")\n",
    "for result in results_table:\n",
    "    print(\"Class: {}\\nPrecision: {:.2f}\\nRecall: {:.2f}\\nF1-Score: {:.2f}\\nCV Score: {:.2f}\\nSupport: {}\\nAnalysis: {}\\n\".format(result['Class'], result['Precision'], result['Recall'], result['F1-Score'], result['cv_score'], result['Support'], result['Analysis']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.3 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, accuracy_score\n",
    "# Define the parameter grid for RandomForest\n",
    "params_rf = {\n",
    "    'n_estimators': [20, 120],\n",
    "    'max_depth':[8,10],\n",
    "    'min_samples_split': [8],\n",
    "    'min_samples_leaf': [4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "test_size = 0.3\n",
    "best_results_rf = {}\n",
    "results_table = []\n",
    "print('Training using Random Forest')\n",
    "for t in targets:\n",
    "    if t == targets[0]: # IS_NNS\n",
    "        # SPLITTING\n",
    "        X = result_df[features_is_nns].values # TODO: Change to features_is_nns\n",
    "        y = result_df[t].values\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42, stratify=y)\n",
    "\n",
    "        # Apply SMOTE\n",
    "        sm = SMOTE(random_state=42)\n",
    "        X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "        # TRAINING\n",
    "        clf_rf = RandomForestClassifier(random_state=42)\n",
    "        random_search = RandomizedSearchCV(clf_rf, param_distributions=params_rf, n_iter=4, cv=5, verbose=0, random_state=42)\n",
    "        random_search.fit(X_train_res, y_train_res)\n",
    "\n",
    "        # PREDICTION\n",
    "        best_rf = random_search.best_estimator_\n",
    "        y_pred_rf = best_rf.predict(X_test)\n",
    "\n",
    "        # EVALUATION\n",
    "        is_f1_rf = f1_score(y_true=y_test, y_pred=y_pred_rf)\n",
    "        is_accuracy_rf = accuracy_score(y_true=y_test, y_pred=y_pred_rf)\n",
    "        is_precision_rf = precision_score(y_true=y_test, y_pred=y_pred_rf)\n",
    "        is_recall_rf = recall_score(y_true=y_test, y_pred=y_pred_rf)\n",
    "        is_support_rf = len(y_test)\n",
    "        \n",
    "        # Analysis is subjective and should be written based on the metrics\n",
    "        if is_precision_rf == 1.0:\n",
    "            analysis = \"The model achieves perfect precision, indicating high confidence in identifying {}. However, it misses about {} of actual {} segments (false negatives).\".format(t, 1-is_recall_rf, t)\n",
    "        else:\n",
    "            analysis = \"The model shows good balance between precision and recall for detecting {}. There's room for improvement in capturing more instances without compromising precision.\".format(t)\n",
    "\n",
    "        results_table.append({\n",
    "            'Class': t,\n",
    "            'Accuracy': is_accuracy_rf,\n",
    "            'Precision': is_precision_rf,\n",
    "            'Recall': is_recall_rf,\n",
    "            'F1-Score': is_f1_rf,\n",
    "            'cv_score': random_search.best_score_,\n",
    "            'Support': is_support_rf,\n",
    "            'Analysis': analysis\n",
    "        })\n",
    "        print(\"-----------------------------------\")\n",
    "        best_results_rf[t] = {\n",
    "            'f1': is_f1_rf,\n",
    "            'recall': is_recall_rf,\n",
    "            'precision': is_precision_rf,\n",
    "            'accuracy': is_accuracy_rf,\n",
    "            'params': random_search.best_params_,\n",
    "            'cv_score': random_search.best_score_,\n",
    "            'test_size': test_size\n",
    "        }\n",
    "\n",
    "        print(f'\\nBest results for target {t} using Random Forest:')\n",
    "        print(f\"Test F1: {best_results_rf[t]['f1']}\")\n",
    "        print(f\"Test Recall: {best_results_rf[t]['recall']}\")\n",
    "        print(f\"Test Precision: {best_results_rf[t]['precision']}\")\n",
    "        print(f\"Test Accuracy: {best_results_rf[t]['accuracy']}\")\n",
    "        print(f\"Best Params: {best_results_rf[t]['params']}\")\n",
    "        print(f\"CV Score: {best_results_rf[t]['cv_score']}\")\n",
    "        print('_')\n",
    "        # Print confusion matrix\n",
    "        cm = confusion_matrix(y_true=y_test, y_pred=y_pred_rf)\n",
    "        cm_display = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "        cm_display.plot()\n",
    "        plt.show()\n",
    "    elif t == targets[1]: # CONTAINS_NNS\n",
    "        # SPLITTING\n",
    "        X = result_df[features_contains_nns].values # TODO: Change to features_contains_nns\n",
    "        y = result_df[t].values\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42, stratify=y)\n",
    "\n",
    "        # Apply SMOTE\n",
    "        sm = SMOTE(random_state=42)\n",
    "        X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "        # TRAINING\n",
    "        clf_rf = RandomForestClassifier(random_state=42)\n",
    "        random_search = RandomizedSearchCV(clf_rf, param_distributions=params_rf, n_iter=4, cv=5, verbose=0, random_state=42)\n",
    "        random_search.fit(X_train_res, y_train_res)\n",
    "\n",
    "        # PREDICTION\n",
    "        best_rf = random_search.best_estimator_\n",
    "        y_pred_rf = best_rf.predict(X_test)\n",
    "\n",
    "        # EVALUATION\n",
    "        contains_f1_rf = f1_score(y_true=y_test, y_pred=y_pred_rf)\n",
    "        contains_accuracy_rf = accuracy_score(y_true=y_test, y_pred=y_pred_rf)\n",
    "        contains_precision_rf = precision_score(y_true=y_test, y_pred=y_pred_rf)\n",
    "        contains_recall_rf = recall_score(y_true=y_test, y_pred=y_pred_rf)\n",
    "        contains_support_rf = len(y_test)\n",
    "        \n",
    "        # Analysis is subjective and should be written based on the metrics\n",
    "        if contains_precision_rf == 1.0:\n",
    "            analysis = \"The model achieves perfect precision, indicating high confidence in identifying {}. However, it misses about {} of actual {} segments (false negatives).\".format(t, 1-contains_recall_rf, t)\n",
    "        else:\n",
    "            analysis = \"The model shows good balance between precision and recall for detecting {}. There's room for improvement in capturing more instances without compromising precision.\".format(t)\n",
    "\n",
    "        results_table.append({\n",
    "            'Class': t,\n",
    "            'Accuracy': contains_accuracy_rf,\n",
    "            'Precision': contains_precision_rf,\n",
    "            'Recall': contains_recall_rf,\n",
    "            'F1-Score': contains_f1_rf,\n",
    "            'cv_score': random_search.best_score_,\n",
    "            'Support': contains_support_rf,\n",
    "            'Analysis': analysis\n",
    "        })\n",
    "        print(\"-----------------------------------\")\n",
    "        best_results_rf[t] = {\n",
    "            'f1': contains_f1_rf,\n",
    "            'recall': contains_recall_rf,\n",
    "            'precision': contains_precision_rf,\n",
    "            'accuracy': contains_accuracy_rf,\n",
    "            'params': random_search.best_params_,\n",
    "            'cv_score': random_search.best_score_,\n",
    "            'test_size': test_size\n",
    "        }\n",
    "\n",
    "        print(f'\\nBest results for target {t} using Random Forest:')\n",
    "        print(f\"Test F1: {best_results_rf[t]['f1']}\")\n",
    "        print(f\"Test Recall: {best_results_rf[t]['recall']}\")\n",
    "        print(f\"Test Precision: {best_results_rf[t]['precision']}\")\n",
    "        print(f\"Test Accuracy: {best_results_rf[t]['accuracy']}\")\n",
    "        print(f\"Best Params: {best_results_rf[t]['params']}\")\n",
    "        print(f\"CV Score: {best_results_rf[t]['cv_score']}\")\n",
    "        print('_')\n",
    "        # Print confusion matrix\n",
    "        cm = confusion_matrix(y_true=y_test, y_pred=y_pred_rf)\n",
    "        cm_display = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "        cm_display.plot()\n",
    "        plt.show()\n",
    "\n",
    "print(\"Analysis\\n\")\n",
    "for result in results_table:\n",
    "    print(\"Class: {}\\nPrecision: {:.2f}\\nRecall: {:.2f}\\nF1-Score: {:.2f}\\nCV Score: {:.2f}\\nSupport: {}\\nAnalysis: {}\\n\".format(result['Class'], result['Precision'], result['Recall'], result['F1-Score'], result['cv_score'], result['Support'], result['Analysis']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Conclusions: Comparison against chance (contains_nns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Comparison of the metrics of IS_NNS for the three models and random predictions\")\n",
    "print(\"-------------------------------------------------------------------------------------\")\n",
    "print(\"Model\\t\\t\\tAccuracy\\tPrecision\\tRecall\\t\\tF1-Score\")\n",
    "print(\"GradientBoosting\\t{:.2f}\\t\\t{:.2f}\\t\\t{:.2f}\\t\\t{:.2f}\".format(is_accuracy_gbc, is_precision_gbc, is_recall_gbc, is_f1_gbc))\n",
    "print(\"GradientBoosting-KFolds\\t{:.2f}\\t\\t{:.2f}\\t\\t{:.2f}\\t\\t{:.2f}\".format(is_accuracy_gbc_kf, is_precision_gbc_kf, is_recall_gbc_kf, is_f1_gbc_kf))\n",
    "print(\"RandomForest\\t\\t{:.2f}\\t\\t{:.2f}\\t\\t{:.2f}\\t\\t{:.2f}\".format(is_accuracy_rf, is_precision_rf, is_recall_rf, is_f1_rf))\n",
    "print(\"-------------------------------------------------------------------------------------\")\n",
    "print(\"Random Predictions\\t{:.2f}\\t\\t{:.2f}\\t\\t{:.2f}\\t\\t{:.2f}\".format(is_random_accuracy, is_random_precision, is_random_recall, is_random_f1))\n",
    "print(\"-------------------------------------------------------------------------------------\")\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Comparison of the metrics of CONTAINS_NNS for the three models and random predictions\")\n",
    "print(\"-------------------------------------------------------------------------------------\")\n",
    "print(\"Model\\t\\t\\tAccuracy\\tPrecision\\tRecall\\t\\tF1-Score\")\n",
    "print(\"GradientBoosting\\t{:.2f}\\t\\t{:.2f}\\t\\t{:.2f}\\t\\t{:.2f}\".format(contains_accuracy_gbc, contains_precision_gbc, contains_recall_gbc, contains_f1_gbc))\n",
    "print(\"GradientBoosting-KFolds\\t{:.2f}\\t\\t{:.2f}\\t\\t{:.2f}\\t\\t{:.2f}\".format(contains_accuracy_gbc_kf, contains_precision_gbc_kf, contains_recall_gbc_kf, contains_f1_gbc_kf))\n",
    "print(\"RandomForest\\t\\t{:.2f}\\t\\t{:.2f}\\t\\t{:.2f}\\t\\t{:.2f}\".format(contains_accuracy_rf, contains_precision_rf, contains_recall_rf, contains_f1_rf))\n",
    "print(\"-------------------------------------------------------------------------------------\")\n",
    "print(\"Random Predictions\\t{:.2f}\\t\\t{:.2f}\\t\\t{:.2f}\\t\\t{:.2f}\".format(contains_random_accuracy, contains_random_precision, contains_random_recall, contains_random_f1))\n",
    "print(\"-------------------------------------------------------------------------------------\")\n",
    "\n",
    "# TODO: ¿¿¿¿¿ Exportar los resultados y las confusion matrices a la carpeta \"results\" ?????"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
