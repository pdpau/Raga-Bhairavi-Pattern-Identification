{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREGUNTES PER AL THOMAS\n",
    "# 2. How to get Melodia working?\n",
    "\n",
    "\n",
    "# FIND 2 PATTERNS AND TRAIN A MODEL TO PREDICT THOSE 2 PATTERNS\n",
    "\n",
    "\n",
    "# Normalizing the cents\n",
    "\n",
    "# Raga Ritigowla\n",
    "\n",
    "\n",
    "# VISUALIZATION\n",
    "# MatPlotLib to visualize the patterns (it's the easiest)\n",
    "# Plotly dash (more complex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Installs and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "!pip install matplotlib\n",
    "!pip install plotly\n",
    "#install all packages needed from this notebook\n",
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install sklearn\n",
    "!pip install librosa\n",
    "!pip install IPython\n",
    "%pip install imblearn\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_kj_path = \"../data/raw/annotations_koti_janmani.txt\"\n",
    "annotations_vnk_path = \"../data/raw/annotations_vanajaksha_ninni_kore.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_seconds(t):\n",
    "    return (t.hour * 60 * 60) + (t.minute * 60) + t.second + (t.microsecond / 1000000)\n",
    "\n",
    "def load_annotations_file(path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load annotations from a file.\n",
    "\n",
    "    :param path: Path to the file containing the annotations.\n",
    "    :return: A pandas DataFrame containing the annotations.\n",
    "    \"\"\"\n",
    "    # Read the annotations file\n",
    "    annotations = pd.read_csv(path, sep='\\t', header=None)\n",
    "\n",
    "    # Add column names\n",
    "    annotations.columns = [\"level\", \"\", \"start\", \"end\", \"duration\", \"label\"]\n",
    "    del annotations[\"\"]\n",
    "\n",
    "    # Convert to seconds\n",
    "    annotations[\"start\"] = pd.to_datetime(annotations[\"start\"])\n",
    "    annotations[\"end\"] = pd.to_datetime(annotations[\"end\"])\n",
    "    annotations[\"start\"] = annotations[\"start\"].apply(to_seconds)\n",
    "    annotations[\"end\"] = annotations[\"end\"].apply(to_seconds)\n",
    "    annotations[\"duration\"] = pd.to_timedelta(annotations['duration']).dt.total_seconds()\n",
    "\n",
    "    annotations.reset_index(inplace=True)\n",
    "\n",
    "    return annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_kj = load_annotations_file(annotations_kj_path)\n",
    "annotations_vnk = load_annotations_file(annotations_vnk_path)\n",
    "\n",
    "#annotations_vnk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_kj_usancara = annotations_kj[annotations_kj[\"level\"] == \"underlying_sancara\"]\n",
    "annotations_vnk_usancara = annotations_vnk[annotations_vnk[\"level\"] == \"root_sancara\"]\n",
    "\n",
    "#annotations_vnk_usancara"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_kj_path = \"../data/raw/Koti Janmani/Koti Janmani.multitrack-vocal.mp3\"\n",
    "audio_vnk_path = \"../data/raw/Vanajaksha Ninne Kori/Vanajaksha Ninne Kori_vocal.mp3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio_file(path: str, sampling_rate: int) -> tuple:\n",
    "    audio_time_series, sr = librosa.load(path, sr=sampling_rate)\n",
    "    return audio_time_series, sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_kj, sr_kj = load_audio_file(audio_kj_path, 44100)\n",
    "audio_vnk, sr_vnk = load_audio_file(audio_vnk_path, 44100)\n",
    "\n",
    "#Audio(data=audio_vnk, rate=sr_vnk)\n",
    "Audio(data=audio_kj, rate=sr_kj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Extract pitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passar la ref a una constant (per fer el canvi de Hz a cents)\n",
    "tonic_path_kj = \"../data/raw/Koti Janmani/Koti Janmani.ctonic.txt\"\n",
    "tonic_path_vnk = \"../data/raw/Vanajaksha Ninne Kori/Vanajaksha Ninne Kori.ctonic.txt\"\n",
    "\n",
    "with open(tonic_path_kj, \"r\") as f:\n",
    "    ctonic_ref_kj = float(f.readline().strip())\n",
    "\n",
    "with open(tonic_path_vnk, \"r\") as f:\n",
    "    ctonic_ref_vnk = float(f.readline().strip())\n",
    "\n",
    "ctonic_ref_vnk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import savgol_filter\n",
    "\n",
    "def pitch_to_cents(pitch: float, ref: float):\n",
    "    if pitch == 0:\n",
    "        return None\n",
    "    else:\n",
    "        return 1200 * math.log(pitch/ref, 2)\n",
    "\n",
    "def interpolate_and_smooth_pitch(pitch):\n",
    "    pitch = pd.Series(pitch)\n",
    "    pitch[pitch <= 0] = np.nan\n",
    "    pitch_interpolated = pitch.interpolate(method=\"linear\")\n",
    "    pitch_smoothed = savgol_filter(pitch_interpolated, window_length=5, polyorder=2)\n",
    "    return pitch_smoothed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract pitch from pitch file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_path_kj = \"../data/raw/Koti Janmani/Koti_Janmani.melodia.pitch.txt\"\n",
    "pitch_path_vnk = \"../data/raw/Vanajaksha Ninne Kori/Vanajaksha Ninne Kori.melodia.pitch.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pitch_file(path: str):\n",
    "    \"\"\"\n",
    "    Load a pitch file from a given path.\n",
    "\n",
    "    :param path: Path to the pitch file.\n",
    "    :return: pitch_file, time, pitch, timestep\n",
    "    \"\"\"\n",
    "    pitch_file = pd.read_csv(path, sep=\"\\t\", header=None)\n",
    "    pitch_file.columns = [\"time\", \"pitch\"]\n",
    "\n",
    "    time = pitch_file[\"time\"].values\n",
    "    pitch = pitch_file[\"pitch\"].values\n",
    "    timestep = time[1] - time[0]\n",
    "\n",
    "    return pitch_file, time, pitch, timestep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_file_kj, time_kj, pitch_kj, timestep_kj = load_pitch_file(pitch_path_kj)\n",
    "pitch_file_vnk, time_vnk, pitch_vnk, timestep_vnk = load_pitch_file(pitch_path_vnk)\n",
    "\n",
    "# Replace non-positive values with NaN, interpolate and smooth\n",
    "pitch_kj_smoothed = interpolate_and_smooth_pitch(pitch_kj)\n",
    "pitch_vnk_smoothed = interpolate_and_smooth_pitch(pitch_vnk)\n",
    "\n",
    "# Convert pitch to cents\n",
    "pitch_cents_kj = np.array([pitch_to_cents(p, ctonic_ref_kj) for p in pitch_kj_smoothed])\n",
    "pitch_cents_vnk = np.array([pitch_to_cents(p, ctonic_ref_vnk) for p in pitch_vnk_smoothed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pitch_cents_kj[10000:10020]\n",
    "pitch_cents_vnk[10000:10020]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pitch was extracted using melodia and saved into the files: \"Koti Janmani.melodia.pitch.txt\" , \"Vanajaksha Ninne Kori.melodia.pitch.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Time Domain Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from librosa.feature import rms\n",
    "from librosa.feature import zero_crossing_rate as zcr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_features_kj_df = annotations_kj_usancara.copy()\n",
    "time_features_vnk_df = annotations_vnk_usancara.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 Root Mean Square Energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rms(audio: np.ndarray, sample_start: float, sample_end: float, sr: int) -> float:\n",
    "    sample = audio[round(sample_start * sr):round(sample_end * sr)]\n",
    "    return np.mean(rms(y=sample)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: a stands for annotation\n",
    "time_features_kj_df['rmse'] = time_features_kj_df.apply(\n",
    "    lambda a: compute_rms(audio_kj, a['start'], a['end'], sr_kj), axis=1\n",
    ")\n",
    "time_features_vnk_df['rmse'] = time_features_vnk_df.apply(\n",
    "    lambda a: compute_rms(audio_vnk, a['start'], a['end'], sr_vnk), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 Zero Crossing Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_zcr(audio: np.ndarray, sample_start: float, sample_end: float, sr: int) -> float:\n",
    "    sample = audio[round(sample_start * sr):round(sample_end * sr)]\n",
    "    return np.mean(zcr(y=sample)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_features_kj_df['zcr'] = time_features_kj_df.apply(\n",
    "    lambda a: compute_zcr(audio_kj, a['start'], a['end'], sr_kj), axis=1\n",
    ")\n",
    "time_features_vnk_df['zcr'] = time_features_vnk_df.apply(\n",
    "    lambda a: compute_zcr(audio_vnk, a['start'], a['end'], sr_vnk), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time Domain Features DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#time_features_kj_df\n",
    "#time_features_vnk_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Frequency Domain Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from librosa.feature import spectral_centroid as scentroid\n",
    "from librosa.feature import spectral_bandwidth as sbandwidth\n",
    "from librosa.feature import spectral_rolloff as srolloff\n",
    "from librosa.feature import mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_features_kj_df = annotations_kj_usancara.copy()\n",
    "frequency_features_vnk_df = annotations_vnk_usancara.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 Band Energy Ratio (not necessary??)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Passar el codi de l'altre notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 Spectral Centroid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each frame of a magnitude spectrogram is normalized and treated as a distribution over frequency bins, from which the mean (centroid) is extracted per frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_scentroid(audio: np.ndarray, sample_start: float, sample_end: float, sr: int) -> float:\n",
    "    sample = audio[round(sample_start * sr):round(sample_end * sr)]\n",
    "    return np.mean(scentroid(y=sample, sr=sr)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_features_kj_df['spectral_centroid'] = frequency_features_kj_df.apply(\n",
    "    lambda a: compute_scentroid(audio_kj, a['start'], a['end'], sr_kj), axis=1\n",
    ")\n",
    "frequency_features_vnk_df['spectral_centroid'] = frequency_features_vnk_df.apply(\n",
    "    lambda a: compute_scentroid(audio_vnk, a['start'], a['end'], sr_vnk), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.3 Spectral Bandwidth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sbandwidth(audio: np.ndarray, sample_start: float, sample_end: float, sr: int) -> float:\n",
    "    sample = audio[round(sample_start * sr):round(sample_end * sr)]\n",
    "    return np.mean(sbandwidth(y=sample, sr=sr)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_features_kj_df['spectral_bandwidth'] = frequency_features_kj_df.apply(\n",
    "    lambda a: compute_sbandwidth(audio_kj, a['start'], a['end'], sr_kj), axis=1\n",
    ")\n",
    "frequency_features_vnk_df['spectral_bandwidth'] = frequency_features_vnk_df.apply(\n",
    "    lambda a: compute_sbandwidth(audio_vnk, a['start'], a['end'], sr_vnk), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.4 Spectral Rolloff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The roll-off frequency is defined for each frame as the center frequency for a spectrogram bin such that at least roll_percent (0.85 by default) of the energy of the spectrum in this frame is contained in this bin and the bins below. This can be used to, e.g., approximate the maximum (or minimum) frequency by setting roll_percent to a value close to 1 (or 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_srolloff(audio: np.ndarray, sample_start: float, sample_end: float, sr: int) -> float:\n",
    "    sample = audio[round(sample_start * sr):round(sample_end * sr)]\n",
    "    return np.mean(srolloff(y=sample, sr=sr)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_features_kj_df['spectral_rolloff'] = frequency_features_kj_df.apply(\n",
    "    lambda a: compute_srolloff(audio_kj, a['start'], a['end'], sr_kj), axis=1\n",
    ")\n",
    "frequency_features_vnk_df['spectral_rolloff'] = frequency_features_vnk_df.apply(\n",
    "    lambda a: compute_srolloff(audio_vnk, a['start'], a['end'], sr_vnk), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.5 Mel Frequency Cepstral Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_kj_df = annotations_kj_usancara.copy()\n",
    "mfcc_vnk_df = annotations_vnk_usancara.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: No fan falta 13... de moment posem 6\n",
    "def compute_mfcc(audio: np.ndarray, sample_start: float, sample_end: float, sr: int) -> np.ndarray:\n",
    "    sample = audio[round(sample_start * sr):round(sample_end * sr)]\n",
    "    return np.mean(mfcc(y=sample, sr=sr, n_mfcc=6), axis=1)\n",
    "\n",
    "mfcc_cols = [f'mfcc_{i+1}' for i in range(6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_kj_df[mfcc_cols] = mfcc_kj_df.apply(\n",
    "    lambda a: compute_mfcc(audio_kj, a['start'], a['end'], sr_kj), axis=1\n",
    ").apply(pd.Series)\n",
    "mfcc_vnk_df[mfcc_cols] = mfcc_vnk_df.apply(\n",
    "    lambda a: compute_mfcc(audio_vnk, a['start'], a['end'], sr_vnk), axis=1\n",
    ").apply(pd.Series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequency Domain Features DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#frequency_features_kj_df\n",
    "#frequency_features_vnk_df\n",
    "mfcc_kj_df\n",
    "#mfcc_vnk_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.4 Spectral Contrast ¿¿??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each frame of a spectrogram S is divided into sub-bands. For each sub-band, the energy contrast is estimated by comparing the mean energy in the top quantile (peak energy) to that of the bottom quantile (valley energy). High contrast values generally correspond to clear, narrow-band signals, while low contrast values correspond to broad-band noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Pitch Curve Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_features_kj_df = annotations_kj_usancara.copy()\n",
    "pitch_features_vnk_df = annotations_vnk_usancara.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1 Mean pitch, Min/Max and Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_min_max_pitch(cents: np.ndarray, tstep: float, sample_start: float, sample_end: float):\n",
    "    #sample_time = time[round(sample_start/tstep):round(sample_end/tstep)]\n",
    "    sample_cents = cents[round(sample_start/tstep):round(sample_end/tstep)]\n",
    "    \"\"\" sample_cents_clean = [x for x in sample_cents if x is not None]\n",
    "    if not sample_cents_clean:\n",
    "        return None \"\"\"\n",
    "    return np.mean(sample_cents), min(sample_cents), max(sample_cents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_features_kj_df[['mean_pitch', 'min_pitch', 'max_pitch']] = pitch_features_kj_df.apply(\n",
    "    lambda a: get_mean_min_max_pitch(pitch_cents_kj, timestep_kj, a['start'], a['end']), axis=1\n",
    ").apply(pd.Series)\n",
    "pitch_features_vnk_df[['mean_pitch', 'min_pitch', 'max_pitch']] = pitch_features_vnk_df.apply(\n",
    "    lambda a: get_mean_min_max_pitch(pitch_cents_vnk, timestep_vnk, a['start'], a['end']), axis=1\n",
    ").apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Range\n",
    "pitch_features_kj_df['pitch_range'] = pitch_features_kj_df['max_pitch'] - pitch_features_kj_df['min_pitch']\n",
    "pitch_features_vnk_df['pitch_range'] = pitch_features_vnk_df['max_pitch'] - pitch_features_vnk_df['min_pitch']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2 Number of Change Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use PROMINENCE to get only significant change points (> 70 cents is significant)\n",
    "\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "def compute_number_of_change_points(cents: np.ndarray, prominence: int, tstep: float, sample_start: float, sample_end: float) -> int:\n",
    "    #sample_time = time[round(sample_start/tstep):round(sample_end/tstep)]\n",
    "    sample_cents = cents[round(sample_start/tstep):round(sample_end/tstep)]\n",
    "\n",
    "    peaks, _ = find_peaks(sample_cents, prominence=prominence)\n",
    "    valleys, _ = find_peaks(-sample_cents, prominence=prominence)\n",
    "\n",
    "    num_change_points = len(peaks) + len(valleys)\n",
    "    return num_change_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prominence = 70 #cents\n",
    "\n",
    "pitch_features_kj_df['num_change_points'] = pitch_features_kj_df.apply(\n",
    "    lambda a: compute_number_of_change_points(pitch_cents_kj, prominence, timestep_kj, a['start'], a['end']), axis=1\n",
    ")\n",
    "pitch_features_vnk_df['num_change_points'] = pitch_features_vnk_df.apply(\n",
    "    lambda a: compute_number_of_change_points(pitch_cents_vnk, prominence, timestep_vnk, a['start'], a['end']), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.3 Number of Change Points per second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_number_of_change_points_per_second(cents: np.ndarray, prominence: int, tstep: float, sample_start: float, sample_end: float) -> float:\n",
    "    num_change_points = compute_number_of_change_points(cents, prominence, tstep, sample_start, sample_end)\n",
    "    return num_change_points / (sample_end - sample_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_features_kj_df['num_change_points_per_second'] = pitch_features_kj_df.apply(\n",
    "    lambda a: compute_number_of_change_points_per_second(pitch_cents_kj, prominence, timestep_kj, a['start'], a['end']), axis=1\n",
    ")\n",
    "pitch_features_vnk_df['num_change_points_per_second'] = pitch_features_vnk_df.apply(\n",
    "    lambda a: compute_number_of_change_points_per_second(pitch_cents_vnk, prominence, timestep_vnk, a['start'], a['end']), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pitch Curve Features DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pitch_features_kj_df\n",
    "#pitch_features_vnk_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Create DataFrame with the Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = [\"index\", \"level\", \"start\", \"end\", \"duration\", \"label\"]\n",
    "features_kj_df = pd.concat([annotations_kj_usancara, \n",
    "                        time_features_kj_df.drop(columns=cols_to_drop),\n",
    "                        frequency_features_kj_df.drop(columns=cols_to_drop),\n",
    "                        mfcc_kj_df.drop(columns=cols_to_drop),\n",
    "                        pitch_features_kj_df.drop(columns=cols_to_drop)],\n",
    "axis=1)\n",
    "features_vnk_df = pd.concat([annotations_vnk_usancara,\n",
    "                        time_features_vnk_df.drop(columns=cols_to_drop),\n",
    "                        frequency_features_vnk_df.drop(columns=cols_to_drop),\n",
    "                        mfcc_vnk_df.drop(columns=cols_to_drop),\n",
    "                        pitch_features_vnk_df.drop(columns=cols_to_drop)],\n",
    "axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge both dataframes\n",
    "features_df = pd.concat([features_kj_df, features_vnk_df], axis=0)\n",
    "features_df['level'] = features_df['level'].apply(lambda y: y.replace('root','underlying'))\n",
    "\n",
    "#features_df[130:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "def normalize_dataframe(df: pd.DataFrame, features) -> pd.DataFrame:\n",
    "    for f in features:\n",
    "        if f != 'num_change_points' and f != 'num_change_points_per_second':\n",
    "            df[f] = (df[f] - df[f].mean()) / df[f].std()\n",
    "        \"\"\" else:\n",
    "            df[f] = df[f] / df['duration'] \"\"\"\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = ['rmse', 'zcr', \n",
    "            'spectral_centroid', 'spectral_bandwidth', 'spectral_rolloff',\n",
    "            'mfcc_1', 'mfcc_2', 'mfcc_3', 'mfcc_4', 'mfcc_5', 'mfcc_6',\n",
    "            'mean_pitch', 'min_pitch', 'max_pitch', 'pitch_range', 'num_change_points', 'num_change_points_per_second']\n",
    "features_pitch = ['mean_pitch', 'min_pitch', 'max_pitch', 'pitch_range', 'num_change_points', 'num_change_points_per_second']\n",
    "\n",
    "norm_features_df = normalize_dataframe(features_df, all_features)\n",
    "norm_features_df[130:150]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing NNS (no subsequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = norm_features_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nns = df[df['label'] == 'nns']\n",
    "df_nns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_multiple_patterns_pitch(pitch_cents_list, time_list, tstep_list, sample_start_list, sample_end_list):\n",
    "    \"\"\"\n",
    "    Compara múltiples patrones de pitch en un solo gráfico.\n",
    "\n",
    "    pitch_cents_list: Lista de arrays de pitch en cents.\n",
    "    time_list: Lista de arrays de tiempo correspondientes.\n",
    "    tstep_list: Lista de pasos de tiempo para cada conjunto de datos.\n",
    "    sample_start_list: Lista de tiempos de inicio para los fragmentos a comparar.\n",
    "    sample_end_list: Lista de tiempos de fin para los fragmentos a comparar.\n",
    "    \"\"\"\n",
    "    colors = ['blue', 'red', 'green', 'purple', 'orange', 'cyan', 'magenta', 'yellow', 'black', 'grey']\n",
    "    num_patterns = len(pitch_cents_list)\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    for i in range(num_patterns):\n",
    "        pitch_cents = pitch_cents_list[i]\n",
    "        time = time_list[i]\n",
    "        tstep = tstep_list[i]\n",
    "        sample_start = sample_start_list[i]\n",
    "        sample_end = sample_end_list[i]\n",
    "        \n",
    "        sample_time = time[round(sample_start/tstep):round(sample_end/tstep)]\n",
    "        sample_time = sample_time - sample_start\n",
    "        sample_cents = pitch_cents[round(sample_start/tstep):round(sample_end/tstep)]\n",
    "        \n",
    "        plt.plot(sample_time, sample_cents, label=f'Pattern {i+1}', color=colors[i % len(colors)])\n",
    "    \n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Pitch (cents)')\n",
    "    plt.legend()\n",
    "    plt.title('Comparison of Pitch Patterns')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_cents_list = [pitch_cents_kj, pitch_cents_kj, pitch_cents_kj, pitch_cents_kj, pitch_cents_kj]\n",
    "time_list = [time_kj, time_kj, time_kj, time_kj, time_kj]\n",
    "tstep_list = [timestep_kj, timestep_kj, timestep_kj, timestep_kj, timestep_kj]\n",
    "sample_start_list = [df_nns['start'].iloc[i] for i in range(0, 5)]\n",
    "sample_end_list = [df_nns['end'].iloc[i] for i in range(0, 5)]\n",
    "\n",
    "compare_multiple_patterns_pitch(pitch_cents_list, time_list, tstep_list, sample_start_list, sample_end_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modelling to predict NNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = norm_features_df.copy()\n",
    "label = 'nns'\n",
    "\n",
    "# Get IS_NNS\n",
    "filtered_df = df[df['label'] == label]\n",
    "dummies_df = pd.get_dummies(filtered_df['label'], prefix='is')\n",
    "result_df = df.join(dummies_df).fillna(False)\n",
    "\n",
    "# Get CONTAINS_NNS\n",
    "result_df['contains_nns'] = result_df['label'].apply(lambda y: label in y)\n",
    "\n",
    "# Convert the labels to a binary format\n",
    "cols_to_convert = [f'is_{label}', f'contains_{label}']\n",
    "result_df[cols_to_convert] = result_df[cols_to_convert].astype(int)\n",
    "result_df[100:120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURES and TARGETS\n",
    "\n",
    "all_features = ['rmse', 'zcr', \n",
    "            'spectral_centroid', 'spectral_bandwidth', 'spectral_rolloff',\n",
    "            'mfcc_1', 'mfcc_2', 'mfcc_3', 'mfcc_4', 'mfcc_5', 'mfcc_6', \n",
    "            'mean_pitch', 'min_pitch', 'max_pitch', 'pitch_range', 'num_change_points', 'num_change_points_per_second']\n",
    "\n",
    "# Eliminate low variance features ¿¿??\n",
    "low_variance_features = []\n",
    "threshold = 0.1\n",
    "\n",
    "for feat in all_features:\n",
    "    std = result_df[feat].std()\n",
    "    mean = result_df[feat].mean()\n",
    "    cv = abs(std / mean)\n",
    "    if cv < threshold:\n",
    "        low_variance_features.append(feat)\n",
    "\n",
    "high_variance_features = [f for f in all_features if f not in low_variance_features]\n",
    "print(\"Low variance features:\", low_variance_features)\n",
    "\n",
    "\n",
    "\n",
    "targets = [f'is_{label}', f'contains_{label}']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Get Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" X = result_df[all_features].values\n",
    "y = result_df[targets[1]].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) # s'ha de justificar el test_size=0.2 amb els tests de l'Oriol\n",
    "len(X_train) \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Train a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# TRAINING with GradientBoostingClassifier and GridSearchCV (only) and EVALUATING\n",
    "params = {\n",
    "    'n_estimators':[10, 50, 100],\n",
    "    'learning_rate':[0.001, 0.01, 0.1, 1],\n",
    "    'max_depth':[2, 4, 8]\n",
    "}\n",
    "for t in targets:\n",
    "    X = result_df[high_variance_features].values\n",
    "    y = result_df[t].values\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "    \n",
    "    clf = GradientBoostingClassifier()\n",
    "    \n",
    "    gs = GridSearchCV(clf, param_grid=params, scoring='f1', cv=5)\n",
    "    gs.fit(X_train, y_train)\n",
    "    \n",
    "    best = gs.best_estimator_\n",
    "    \n",
    "    y_pred = best.predict(X_test)\n",
    "    \n",
    "    f1 = f1_score(y_pred, y_test)\n",
    "    print(f'Test f1 for target {t}: {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainig with GradientBoostingClassifier using GridSearchCV with StratifiedKFold cross-validation.\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "params = {\n",
    "    'n_estimators':[10, 50, 100],\n",
    "    'learning_rate': [0.001, 0.01, 0.05, 0.1, 0.2, 0.3],\n",
    "    'max_depth': [2, 4, 6, 8, 10]\n",
    "}\n",
    "test_size = 0.2\n",
    "best_results = {}\n",
    "print ('Training with GradientBoostingClassifier using GridSearchCV with StratifiedKFold cross-validation.')\n",
    "for t in targets:\n",
    "    X = result_df[high_variance_features].values\n",
    "    y = result_df[t].values\n",
    "\n",
    "    # Splitting the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42, stratify=y)\n",
    "\n",
    "    clf = GradientBoostingClassifier()\n",
    "    skf = StratifiedKFold(n_splits=5)\n",
    "    gs = GridSearchCV(clf, param_grid=params, scoring='f1', cv=skf)\n",
    "    gs.fit(X_train, y_train)\n",
    "\n",
    "    best = gs.best_estimator_\n",
    "    y_pred = best.predict(X_test)\n",
    "    f1 = f1_score(y_pred, y_test)\n",
    "\n",
    "    best_results[t] = {\n",
    "        'f1': f1,\n",
    "        'params': gs.best_params_,\n",
    "        'cv_score': gs.best_score_,\n",
    "        'test_size': test_size\n",
    "    }\n",
    "\n",
    "# Print overall best results for each target\n",
    "for t in best_results:\n",
    "    print(f'\\nBest results for target {t}:')\n",
    "    print(f\"Test F1: {best_results[t]['f1']}\")\n",
    "    print(f\"Best Params: {best_results[t]['params']}\")\n",
    "    print(f\"CV Score: {best_results[t]['cv_score']}\")\n",
    "    print('_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainig with RandomForest using RandomizedSearchCV with StratifiedKFold cross-validation and SMOTE.\n",
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Define the parameter grid for RandomForest\n",
    "params_rf = {\n",
    "    'n_estimators': [5, 10, 20],\n",
    "    'max_depth': [None, 2, 4, 6, 8, 10],\n",
    "    'min_samples_split': [2, 4, 8],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "test_size = 0.20\n",
    "best_results_rf = {}\n",
    "print ('Training using Random Forest')\n",
    "\n",
    "for t in targets:\n",
    "    X = result_df[high_variance_features].values\n",
    "    y = result_df[t].values\n",
    "\n",
    "    # Splitting the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42, stratify=y)\n",
    "\n",
    "    # Apply SMOTE\n",
    "    sm = SMOTE(random_state=42)\n",
    "    X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
    "    \n",
    "    clf_rf = RandomForestClassifier()\n",
    "    random_search = RandomizedSearchCV(clf_rf, param_distributions=params_rf, n_iter=50, cv=3, verbose=2, random_state=42, n_jobs=-1)\n",
    "    random_search.fit(X_train_res, y_train_res)\n",
    "    best_rf = random_search.best_estimator_\n",
    "    y_pred_rf = best_rf.predict(X_test)\n",
    "    \n",
    "    f1_rf = f1_score(y_pred_rf, y_test)\n",
    "    \n",
    "    best_results_rf[t] = {\n",
    "        'f1': f1_rf,\n",
    "        'params': random_search.best_params_,\n",
    "        'cv_score': random_search.best_score_,\n",
    "        'test_size': test_size\n",
    "    }\n",
    "# Print overall best results for each target\n",
    "for t in best_results_rf:\n",
    "    print(f'\\nBest results for target {t} using Random Forest:')\n",
    "    print(f\"Test F1: {best_results_rf[t]['f1']}\")\n",
    "    print(f\"Best Params: {best_results_rf[t]['params']}\")\n",
    "    print(f\"CV Score: {best_results_rf[t]['cv_score']}\")\n",
    "    print('_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" y_pred = best_clf.predict(X_test)\n",
    "# y_pred = clf.predict(X_test)\n",
    "f1_score(y_pred, y_test) \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
