{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREGUNTES PER AL THOMAS\n",
    "# 2. How to get Melodia working?\n",
    "\n",
    "\n",
    "# FIND 2 PATTERNS AND TRAIN A MODEL TO PREDICT THOSE 2 PATTERNS\n",
    "\n",
    "\n",
    "# Normalizing the cents\n",
    "\n",
    "# Raga Ritigowla\n",
    "\n",
    "\n",
    "# VISUALIZATION\n",
    "# MatPlotLib to visualize the patterns (it's the easiest)\n",
    "# Plotly dash (more complex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_kj_path = \"../data/raw/annotations_koti_janmani.txt\"\n",
    "annotations_vnk_path = \"../data/raw/annotations_vanajaksha_ninni_kore.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_seconds(t):\n",
    "    return (t.hour * 60 * 60) + (t.minute * 60) + t.second + (t.microsecond / 1000000)\n",
    "\n",
    "def load_annotations_file(path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load annotations from a file.\n",
    "\n",
    "    :param path: Path to the file containing the annotations.\n",
    "    :return: A pandas DataFrame containing the annotations.\n",
    "    \"\"\"\n",
    "    # Read the annotations file\n",
    "    annotations = pd.read_csv(path, sep='\\t', header=None)\n",
    "\n",
    "    # Add column names\n",
    "    annotations.columns = [\"level\", \"\", \"start\", \"end\", \"duration\", \"label\"]\n",
    "    del annotations[\"\"]\n",
    "\n",
    "    # Convert to seconds\n",
    "    annotations[\"start\"] = pd.to_datetime(annotations[\"start\"])\n",
    "    annotations[\"end\"] = pd.to_datetime(annotations[\"end\"])\n",
    "    annotations[\"start\"] = annotations[\"start\"].apply(to_seconds)\n",
    "    annotations[\"end\"] = annotations[\"end\"].apply(to_seconds)\n",
    "    annotations[\"duration\"] = pd.to_timedelta(annotations['duration']).dt.total_seconds()\n",
    "\n",
    "    annotations.reset_index(inplace=True)\n",
    "\n",
    "    return annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_kj = load_annotations_file(annotations_kj_path)\n",
    "annotations_vnk = load_annotations_file(annotations_vnk_path)\n",
    "\n",
    "#annotations_vnk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_kj_usancara = annotations_kj[annotations_kj[\"level\"] == \"underlying_sancara\"]\n",
    "annotations_vnk_usancara = annotations_vnk[annotations_vnk[\"level\"] == \"root_sancara\"]\n",
    "\n",
    "#annotations_vnk_usancara"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_kj_path = \"../data/raw/Koti Janmani/Koti Janmani.multitrack-vocal.mp3\"\n",
    "audio_vnk_path = \"../data/raw/Vanajaksha Ninne Kori/Vanajaksha Ninne Kori_vocal.mp3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio_file(path: str, sampling_rate: int) -> tuple:\n",
    "    audio_time_series, sr = librosa.load(path, sr=sampling_rate)\n",
    "    return audio_time_series, sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_kj, sr_kj = load_audio_file(audio_kj_path, 44100)\n",
    "audio_vnk, sr_vnk = load_audio_file(audio_vnk_path, 44100)\n",
    "\n",
    "#Audio(data=audio_vnk, rate=sr_vnk)\n",
    "Audio(data=audio_kj, rate=sr_kj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Extract pitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passar la ref a una constant (per fer el canvi de Hz a cents)\n",
    "tonic_path_kj = \"../data/raw/Koti Janmani/Koti Janmani.ctonic.txt\"\n",
    "tonic_path_vnk = \"../data/raw/Vanajaksha Ninne Kori/Vanajaksha Ninne Kori.ctonic.txt\"\n",
    "\n",
    "with open(tonic_path_kj, \"r\") as f:\n",
    "    ctonic_ref_kj = float(f.readline().strip())\n",
    "\n",
    "with open(tonic_path_vnk, \"r\") as f:\n",
    "    ctonic_ref_vnk = float(f.readline().strip())\n",
    "\n",
    "ctonic_ref_vnk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import savgol_filter\n",
    "\n",
    "def pitch_to_cents(pitch: float, ref: float):\n",
    "    if pitch == 0:\n",
    "        return None\n",
    "    else:\n",
    "        return 1200 * math.log(pitch/ref, 2)\n",
    "\n",
    "def interpolate_and_smooth_pitch(pitch):\n",
    "    pitch = pd.Series(pitch)\n",
    "    pitch[pitch <= 0] = np.nan\n",
    "    pitch_interpolated = pitch.interpolate(method=\"linear\")\n",
    "    pitch_smoothed = savgol_filter(pitch_interpolated, window_length=5, polyorder=2)\n",
    "    return pitch_smoothed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract pitch from pitch file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_path_kj = \"../data/raw/Koti Janmani/Koti_Janmani.melodia.pitch.txt\"\n",
    "pitch_path_vnk = \"../data/raw/Vanajaksha Ninne Kori/Vanajaksha Ninne Kori.melodia.pitch.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pitch_file(path: str):\n",
    "    \"\"\"\n",
    "    Load a pitch file from a given path.\n",
    "\n",
    "    :param path: Path to the pitch file.\n",
    "    :return: pitch_file, time, pitch, timestep\n",
    "    \"\"\"\n",
    "    pitch_file = pd.read_csv(path, sep=\"\\t\", header=None)\n",
    "    pitch_file.columns = [\"time\", \"pitch\"]\n",
    "\n",
    "    time = pitch_file[\"time\"].values\n",
    "    pitch = pitch_file[\"pitch\"].values\n",
    "    timestep = time[1] - time[0]\n",
    "\n",
    "    return pitch_file, time, pitch, timestep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_file_kj, time_kj, pitch_kj, timestep_kj = load_pitch_file(pitch_path_kj)\n",
    "pitch_file_vnk, time_vnk, pitch_vnk, timestep_vnk = load_pitch_file(pitch_path_vnk)\n",
    "\n",
    "# Replace non-positive values with NaN, interpolate and smooth\n",
    "pitch_kj_smoothed = interpolate_and_smooth_pitch(pitch_kj)\n",
    "pitch_vnk_smoothed = interpolate_and_smooth_pitch(pitch_vnk)\n",
    "\n",
    "# Convert pitch to cents\n",
    "pitch_cents_kj = np.array([pitch_to_cents(p, ctonic_ref_kj) for p in pitch_kj_smoothed])\n",
    "pitch_cents_vnk = np.array([pitch_to_cents(p, ctonic_ref_vnk) for p in pitch_vnk_smoothed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pitch_cents_kj[10000:10020]\n",
    "pitch_cents_vnk[10000:10020]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pitch was extracted using melodia and saved into the files: \"Koti Janmani.melodia.pitch.txt\" , \"Vanajaksha Ninne Kori.melodia.pitch.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Time Domain Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from librosa.feature import rms\n",
    "from librosa.feature import zero_crossing_rate as zcr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_features_kj_df = annotations_kj_usancara.copy()\n",
    "time_features_vnk_df = annotations_vnk_usancara.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 Root Mean Square Energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rms(audio: np.ndarray, sample_start: float, sample_end: float, sr: int) -> float:\n",
    "    sample = audio[round(sample_start * sr):round(sample_end * sr)]\n",
    "    return np.mean(rms(y=sample)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: a stands for annotation\n",
    "time_features_kj_df['rmse'] = time_features_kj_df.apply(\n",
    "    lambda a: compute_rms(audio_kj, a['start'], a['end'], sr_kj), axis=1\n",
    ")\n",
    "time_features_vnk_df['rmse'] = time_features_vnk_df.apply(\n",
    "    lambda a: compute_rms(audio_vnk, a['start'], a['end'], sr_vnk), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 Zero Crossing Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_zcr(audio: np.ndarray, sample_start: float, sample_end: float, sr: int) -> float:\n",
    "    sample = audio[round(sample_start * sr):round(sample_end * sr)]\n",
    "    return np.mean(zcr(y=sample)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_features_kj_df['zcr'] = time_features_kj_df.apply(\n",
    "    lambda a: compute_zcr(audio_kj, a['start'], a['end'], sr_kj), axis=1\n",
    ")\n",
    "time_features_vnk_df['zcr'] = time_features_vnk_df.apply(\n",
    "    lambda a: compute_zcr(audio_vnk, a['start'], a['end'], sr_vnk), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time Domain Features DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#time_features_kj_df\n",
    "#time_features_vnk_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Frequency Domain Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from librosa.feature import spectral_centroid as scentroid\n",
    "from librosa.feature import spectral_bandwidth as sbandwidth\n",
    "from librosa.feature import spectral_rolloff as srolloff\n",
    "from librosa.feature import mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_features_kj_df = annotations_kj_usancara.copy()\n",
    "frequency_features_vnk_df = annotations_vnk_usancara.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 Band Energy Ratio (not necessary??)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Passar el codi de l'altre notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 Spectral Centroid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each frame of a magnitude spectrogram is normalized and treated as a distribution over frequency bins, from which the mean (centroid) is extracted per frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_scentroid(audio: np.ndarray, sample_start: float, sample_end: float, sr: int) -> float:\n",
    "    sample = audio[round(sample_start * sr):round(sample_end * sr)]\n",
    "    return np.mean(scentroid(y=sample, sr=sr)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_features_kj_df['spectral_centroid'] = frequency_features_kj_df.apply(\n",
    "    lambda a: compute_scentroid(audio_kj, a['start'], a['end'], sr_kj), axis=1\n",
    ")\n",
    "frequency_features_vnk_df['spectral_centroid'] = frequency_features_vnk_df.apply(\n",
    "    lambda a: compute_scentroid(audio_vnk, a['start'], a['end'], sr_vnk), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.3 Spectral Bandwidth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sbandwidth(audio: np.ndarray, sample_start: float, sample_end: float, sr: int) -> float:\n",
    "    sample = audio[round(sample_start * sr):round(sample_end * sr)]\n",
    "    return np.mean(sbandwidth(y=sample, sr=sr)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_features_kj_df['spectral_bandwidth'] = frequency_features_kj_df.apply(\n",
    "    lambda a: compute_sbandwidth(audio_kj, a['start'], a['end'], sr_kj), axis=1\n",
    ")\n",
    "frequency_features_vnk_df['spectral_bandwidth'] = frequency_features_vnk_df.apply(\n",
    "    lambda a: compute_sbandwidth(audio_vnk, a['start'], a['end'], sr_vnk), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.4 Spectral Rolloff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The roll-off frequency is defined for each frame as the center frequency for a spectrogram bin such that at least roll_percent (0.85 by default) of the energy of the spectrum in this frame is contained in this bin and the bins below. This can be used to, e.g., approximate the maximum (or minimum) frequency by setting roll_percent to a value close to 1 (or 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_srolloff(audio: np.ndarray, sample_start: float, sample_end: float, sr: int) -> float:\n",
    "    sample = audio[round(sample_start * sr):round(sample_end * sr)]\n",
    "    return np.mean(srolloff(y=sample, sr=sr)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_features_kj_df['spectral_rolloff'] = frequency_features_kj_df.apply(\n",
    "    lambda a: compute_srolloff(audio_kj, a['start'], a['end'], sr_kj), axis=1\n",
    ")\n",
    "frequency_features_vnk_df['spectral_rolloff'] = frequency_features_vnk_df.apply(\n",
    "    lambda a: compute_srolloff(audio_vnk, a['start'], a['end'], sr_vnk), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.5 Mel Frequency Cepstral Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_kj_df = annotations_kj_usancara.copy()\n",
    "mfcc_vnk_df = annotations_vnk_usancara.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: No fan falta 13... de moment posem 6\n",
    "def compute_mfcc(audio: np.ndarray, sample_start: float, sample_end: float, sr: int) -> np.ndarray:\n",
    "    sample = audio[round(sample_start * sr):round(sample_end * sr)]\n",
    "    return np.mean(mfcc(y=sample, sr=sr, n_mfcc=6), axis=1)\n",
    "\n",
    "mfcc_cols = [f'mfcc_{i+1}' for i in range(6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_kj_df[mfcc_cols] = mfcc_kj_df.apply(\n",
    "    lambda a: compute_mfcc(audio_kj, a['start'], a['end'], sr_kj), axis=1\n",
    ").apply(pd.Series)\n",
    "mfcc_vnk_df[mfcc_cols] = mfcc_vnk_df.apply(\n",
    "    lambda a: compute_mfcc(audio_vnk, a['start'], a['end'], sr_vnk), axis=1\n",
    ").apply(pd.Series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequency Domain Features DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#frequency_features_kj_df\n",
    "#frequency_features_vnk_df\n",
    "mfcc_kj_df\n",
    "#mfcc_vnk_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.4 Spectral Contrast ¿¿??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each frame of a spectrogram S is divided into sub-bands. For each sub-band, the energy contrast is estimated by comparing the mean energy in the top quantile (peak energy) to that of the bottom quantile (valley energy). High contrast values generally correspond to clear, narrow-band signals, while low contrast values correspond to broad-band noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Pitch Curve Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_features_kj_df = annotations_kj_usancara.copy()\n",
    "pitch_features_vnk_df = annotations_vnk_usancara.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1 Mean pitch, Min/Max and Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_min_max_pitch(cents: np.ndarray, tstep: float, sample_start: float, sample_end: float):\n",
    "    #sample_time = time[round(sample_start/tstep):round(sample_end/tstep)]\n",
    "    sample_cents = cents[round(sample_start/tstep):round(sample_end/tstep)]\n",
    "    \"\"\" sample_cents_clean = [x for x in sample_cents if x is not None]\n",
    "    if not sample_cents_clean:\n",
    "        return None \"\"\"\n",
    "    return np.mean(sample_cents), min(sample_cents), max(sample_cents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_features_kj_df[['mean_pitch', 'min_pitch', 'max_pitch']] = pitch_features_kj_df.apply(\n",
    "    lambda a: get_mean_min_max_pitch(pitch_cents_kj, timestep_kj, a['start'], a['end']), axis=1\n",
    ").apply(pd.Series)\n",
    "pitch_features_vnk_df[['mean_pitch', 'min_pitch', 'max_pitch']] = pitch_features_vnk_df.apply(\n",
    "    lambda a: get_mean_min_max_pitch(pitch_cents_vnk, timestep_vnk, a['start'], a['end']), axis=1\n",
    ").apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Range\n",
    "pitch_features_kj_df['pitch_range'] = pitch_features_kj_df['max_pitch'] - pitch_features_kj_df['min_pitch']\n",
    "pitch_features_vnk_df['pitch_range'] = pitch_features_vnk_df['max_pitch'] - pitch_features_vnk_df['min_pitch']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2 Number of Change Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use PROMINENCE to get only significant change points (> 70 cents is significant)\n",
    "\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "def compute_number_of_change_points(cents: np.ndarray, prominence: int, tstep: float, sample_start: float, sample_end: float) -> int:\n",
    "    #sample_time = time[round(sample_start/tstep):round(sample_end/tstep)]\n",
    "    sample_cents = cents[round(sample_start/tstep):round(sample_end/tstep)]\n",
    "\n",
    "    peaks, _ = find_peaks(sample_cents, prominence=prominence)\n",
    "    valleys, _ = find_peaks(-sample_cents, prominence=prominence)\n",
    "\n",
    "    num_change_points = len(peaks) + len(valleys)\n",
    "    return num_change_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prominence = 70 #cents\n",
    "\n",
    "pitch_features_kj_df['num_change_points'] = pitch_features_kj_df.apply(\n",
    "    lambda a: compute_number_of_change_points(pitch_cents_kj, prominence, timestep_kj, a['start'], a['end']), axis=1\n",
    ")\n",
    "pitch_features_vnk_df['num_change_points'] = pitch_features_vnk_df.apply(\n",
    "    lambda a: compute_number_of_change_points(pitch_cents_vnk, prominence, timestep_vnk, a['start'], a['end']), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.3 Number of Change Points per second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_number_of_change_points_per_second(cents: np.ndarray, prominence: int, tstep: float, sample_start: float, sample_end: float) -> float:\n",
    "    num_change_points = compute_number_of_change_points(cents, prominence, tstep, sample_start, sample_end)\n",
    "    return num_change_points / (sample_end - sample_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_features_kj_df['num_change_points_per_second'] = pitch_features_kj_df.apply(\n",
    "    lambda a: compute_number_of_change_points_per_second(pitch_cents_kj, prominence, timestep_kj, a['start'], a['end']), axis=1\n",
    ")\n",
    "pitch_features_vnk_df['num_change_points_per_second'] = pitch_features_vnk_df.apply(\n",
    "    lambda a: compute_number_of_change_points_per_second(pitch_cents_vnk, prominence, timestep_vnk, a['start'], a['end']), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pitch Curve Features DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pitch_features_kj_df\n",
    "#pitch_features_vnk_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Create DataFrame with the Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = [\"index\", \"level\", \"start\", \"end\", \"duration\", \"label\"]\n",
    "features_kj_df = pd.concat([annotations_kj_usancara, \n",
    "                        time_features_kj_df.drop(columns=cols_to_drop),\n",
    "                        frequency_features_kj_df.drop(columns=cols_to_drop),\n",
    "                        mfcc_kj_df.drop(columns=cols_to_drop),\n",
    "                        pitch_features_kj_df.drop(columns=cols_to_drop)],\n",
    "axis=1)\n",
    "features_vnk_df = pd.concat([annotations_vnk_usancara,\n",
    "                        time_features_vnk_df.drop(columns=cols_to_drop),\n",
    "                        frequency_features_vnk_df.drop(columns=cols_to_drop),\n",
    "                        mfcc_vnk_df.drop(columns=cols_to_drop),\n",
    "                        pitch_features_vnk_df.drop(columns=cols_to_drop)],\n",
    "axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge both dataframes\n",
    "features_df = pd.concat([features_kj_df, features_vnk_df], axis=0)\n",
    "features_df['level'] = features_df['level'].apply(lambda y: y.replace('root','underlying'))\n",
    "\n",
    "features_df[130:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "def normalize_dataframe(df: pd.DataFrame, features) -> pd.DataFrame:\n",
    "    for f in features:\n",
    "        if f != 'num_change_points' and f != 'num_change_points_per_second':\n",
    "            df[f] = (df[f] - df[f].mean()) / df[f].std()\n",
    "        \"\"\" else:\n",
    "            df[f] = df[f] / df['duration'] \"\"\"\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['rmse', 'zcr', \n",
    "            'spectral_centroid', 'spectral_bandwidth', 'spectral_rolloff',\n",
    "            'mfcc_1', 'mfcc_2', 'mfcc_3', 'mfcc_4', 'mfcc_5', 'mfcc_6']\n",
    "features_pitch = ['mean_pitch', 'min_pitch', 'max_pitch', 'pitch_range', 'num_change_points', 'num_change_points_per_second']\n",
    "\n",
    "norm_features_df = normalize_dataframe(features_df, features)\n",
    "norm_features_df[130:150]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing patterns with the same label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = norm_features_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'].value_counts().head(5)\n",
    "# Our most common patterns are\n",
    "# 1. sssnnpn\n",
    "# 2. sndn\n",
    "# 3. sggm\n",
    "# 4. pmgrs\n",
    "# 5. gmn\n",
    "df_trial = df[df['label'] == 'sssnnpn']\n",
    "#df_trial.to_csv('sssnnpn.csv', index=False)\n",
    "df_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_multiple_patterns_pitch(pitch_cents_list, time_list, tstep_list, sample_start_list, sample_end_list):\n",
    "    \"\"\"\n",
    "    Compara múltiples patrones de pitch en un solo gráfico.\n",
    "\n",
    "    pitch_cents_list: Lista de arrays de pitch en cents.\n",
    "    time_list: Lista de arrays de tiempo correspondientes.\n",
    "    tstep_list: Lista de pasos de tiempo para cada conjunto de datos.\n",
    "    sample_start_list: Lista de tiempos de inicio para los fragmentos a comparar.\n",
    "    sample_end_list: Lista de tiempos de fin para los fragmentos a comparar.\n",
    "    \"\"\"\n",
    "    colors = ['blue', 'red', 'green', 'purple', 'orange', 'cyan', 'magenta', 'yellow', 'black', 'grey']\n",
    "    num_patterns = len(pitch_cents_list)\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    for i in range(num_patterns):\n",
    "        pitch_cents = pitch_cents_list[i]\n",
    "        time = time_list[i]\n",
    "        tstep = tstep_list[i]\n",
    "        sample_start = sample_start_list[i]\n",
    "        sample_end = sample_end_list[i]\n",
    "        \n",
    "        sample_time = time[round(sample_start/tstep):round(sample_end/tstep)]\n",
    "        sample_time = sample_time - sample_start\n",
    "        sample_cents = pitch_cents[round(sample_start/tstep):round(sample_end/tstep)]\n",
    "        \n",
    "        plt.plot(sample_time, sample_cents, label=f'Pattern {i+1}', color=colors[i % len(colors)])\n",
    "    \n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Pitch (cents)')\n",
    "    plt.legend()\n",
    "    plt.title('Comparison of Pitch Patterns')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_cents_list = [pitch_cents_vnk, pitch_cents_vnk, pitch_cents_vnk, pitch_cents_vnk, pitch_cents_vnk]\n",
    "time_list = [time_vnk, time_vnk, time_vnk, time_vnk, time_vnk]\n",
    "tstep_list = [timestep_vnk, timestep_vnk, timestep_vnk, timestep_vnk, timestep_vnk]\n",
    "sample_start_list = [df_trial['start'].iloc[i] for i in range(5, 10)]\n",
    "sample_end_list = [df_trial['end'].iloc[i] for i in range(5, 10)]\n",
    "\n",
    "compare_multiple_patterns_pitch(pitch_cents_list, time_list, tstep_list, sample_start_list, sample_end_list)\n",
    "\n",
    "# Els dos patterns de dalt els canta una germana\n",
    "# Els tres de baix els canta una altra germana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" df = features_df.copy()\n",
    "df_nns = df[df['label'] == 'nns']\n",
    "df_nns \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = norm_features_df.copy()\n",
    "df['label'].value_counts().head(5)\n",
    "# Our most common patterns are\n",
    "# 1. sssnnpn\n",
    "# 2. sndn\n",
    "# 3. sggm\n",
    "# 4. pmgrs\n",
    "# 5. gmn\n",
    "labels = ['sssnnpn', 'sndn', 'sggm', 'pmgrs', 'gmn']\n",
    "\n",
    "# Now i want to get dummies of these three labels\n",
    "filtered_df = df[df['label'].isin(labels)]\n",
    "\n",
    "dummies_df = pd.get_dummies(filtered_df['label'], prefix='is')\n",
    "\n",
    "result_df = df.join(dummies_df).fillna(False)\n",
    "result_df[130:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = features + features_pitch #\"features\" are normalized and \"features_pitch\" are not\n",
    "\n",
    "# TODO: Evaluate if each feature is significant or not\n",
    "# Comparem les mitjanes de cada feature per a cada pattern (els 5 mes comuns)\n",
    "# Si la mitjana es diferent d'un pattern al no_pattern, es probable que sigui un feature significatiu\n",
    "for label in labels:\n",
    "    for feat in all_features:\n",
    "        df_label = result_df[result_df[f'is_{label}'] == True]\n",
    "        df_no_label = result_df[result_df[f'is_{label}'] != True]\n",
    "        print(\"Pattern:\", label, \"| Feature:\", feat)\n",
    "        print(\"Mean of feature\", f\"{feat}\", \"for pattern\", f\"{label}:\", np.mean(df_label[feat]))\n",
    "        print(\"Mean of feature\", f\"{feat}\", \"for other patterns:\", np.mean(df_no_label[feat]))\n",
    "        print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codi exemple\n",
    "\"\"\" df_ns = df[df['is_nns']==1]\n",
    "df_no_ns = df[df['is_nns']!=1]\n",
    "print(np.mean(df_ns[feature]))\n",
    "print(np.mean(df_no_ns[feature])) \"\"\"\n",
    "\n",
    "# Codi exemple contains pattern\n",
    "\"\"\" joined['contains_nns']=joined['label'].apply(lambda y: 'nns' in y)\n",
    "\n",
    "joined['contains_nns'] \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = norm_features_df.copy()\n",
    "df['label'].value_counts().head(5)\n",
    "# Our most common patterns are\n",
    "# 1. sssnnpn\n",
    "# 2. sndn\n",
    "# 3. sggm\n",
    "# 4. pmgrs\n",
    "# 5. gmn\n",
    "labels = ['sssnnpn', 'sndn', 'sggm', 'pmgrs', 'gmn']\n",
    "\n",
    "# Now i want to get dummies of these three labels\n",
    "filtered_df = df[df['label'].isin(labels)]\n",
    "\n",
    "dummies_df = pd.get_dummies(filtered_df['label'], prefix='is')\n",
    "\n",
    "result_df = df.join(dummies_df).fillna(False)\n",
    "result_df[130:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Revisar les \"low variance features\" (exec 55 del pdf del Wilian)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Get Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Falten BER.\n",
    "all_features = ['rmse', 'zcr', \n",
    "            'spectral_centroid', 'spectral_bandwidth', 'spectral_rolloff',\n",
    "            'mfcc_1', 'mfcc_2', 'mfcc_3', 'mfcc_4', 'mfcc_5', 'mfcc_6', \n",
    "            'mean_pitch', 'min_pitch', 'max_pitch', 'pitch_range', 'num_change_points']\n",
    "\n",
    "# 5 most common patterns (no subpatterns yet)\n",
    "target1 = 'is_sssnnpn'\n",
    "target2 = 'is_{pattern}'\n",
    "target3 = 'is_{pattern}'\n",
    "target4 = 'is_{pattern}'\n",
    "target5 = 'is_{pattern}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = result_df[all_features].values\n",
    "y = result_df[target1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "len(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Train a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME: ...\n",
    "\n",
    "params = {\n",
    "    'n_estimators':[10,50,100],\n",
    "    'learning_rate':[0.001,0.01,0.1,1],\n",
    "    'max_depth':[2, 4, 8],\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(clf, param_grid=params, scoring='f1', cv=2)\n",
    "gs.fit(X_train, y_train)\n",
    "best_clf = gs.best_estimator_\n",
    "pd.DataFrame(gs.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clf.predict(X_test)\n",
    "y_pred = best_clf.predict(X_test)\n",
    "f1_score(y_pred, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
