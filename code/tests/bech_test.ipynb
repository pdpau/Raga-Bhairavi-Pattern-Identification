{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREGUNTES PER AL THOMAS\n",
    "# 1. Pitch interpolated and smoothed? (The first row returns NaN)\n",
    "# 2. How to get Melodia working?\n",
    "# 3. \n",
    "# 4.\n",
    "'''\n",
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install matplotlib\n",
    "!pip install IPython\n",
    "'''\n",
    "!pip install librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gdown\n",
    "!pip install configobj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install compiam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_path = \"../data/raw/annotations_koti_janmani.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_seconds(t):\n",
    "    return (t.hour * 60 * 60) + (t.minute * 60) + t.second + (t.microsecond / 1000000)\n",
    "\n",
    "def load_annotations_file(path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load annotations from a file.\n",
    "\n",
    "    :param path: Path to the file containing the annotations.\n",
    "    :return: A pandas DataFrame containing the annotations.\n",
    "    \"\"\"\n",
    "    # Read the annotations file\n",
    "    annotations = pd.read_csv(path, sep='\\t', header=None)\n",
    "\n",
    "    # Add column names\n",
    "    annotations.columns = [\"level\", \"\", \"start\", \"end\", \"duration\", \"label\"]\n",
    "    del annotations[\"\"]\n",
    "\n",
    "    # Convert to seconds\n",
    "    annotations[\"start\"] = pd.to_datetime(annotations[\"start\"])\n",
    "    annotations[\"end\"] = pd.to_datetime(annotations[\"end\"])\n",
    "    annotations[\"start\"] = annotations[\"start\"].apply(to_seconds)\n",
    "    annotations[\"end\"] = annotations[\"end\"].apply(to_seconds)\n",
    "\n",
    "    annotations.reset_index(inplace=True)\n",
    "\n",
    "    return annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_kj = load_annotations_file(annotations_path)\n",
    "annotations_kj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_sancara = annotations_kj[annotations_kj[\"level\"] == \"sancara\"]\n",
    "annotations_sancara"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = \"../data/raw/Koti Janmani/Koti Janmani.multitrack-vocal.mp3\"\n",
    "#audio_path = \"../data/raw/Vanajaksha Ninne Kori/Vanajaksha Ninne Kori_vocal.mp3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio_file(path: str, sampling_rate: int) -> tuple:\n",
    "    audio_time_series, sr = librosa.load(path, sr=sampling_rate)\n",
    "    return audio_time_series, sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_kj, sr_kj = load_audio_file(audio_path, 44100)\n",
    "Audio(data=audio_kj, rate=sr_kj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Extract pitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passar la ref del \"Koti Janmani.ctonic.txt\" a una constant (per fer el canvi de Hz a cents)\n",
    "tonic_path = \"../data/raw/Koti Janmani/Koti Janmani.ctonic.txt\"\n",
    "\n",
    "with open(tonic_path, \"r\") as f:\n",
    "    ctonic_ref = float(f.readline().strip())\n",
    "\n",
    "ctonic_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import savgol_filter\n",
    "\n",
    "def pitch_to_cents(pitch: float, ref: float):\n",
    "    if pitch == 0:\n",
    "        return None\n",
    "    else:\n",
    "        return 1200 * math.log(pitch/ref, 2)\n",
    "\n",
    "def interpolate_and_smooth_pitch(pitch):\n",
    "    pitch = pd.Series(pitch)\n",
    "    pitch[pitch <= 0] = np.nan\n",
    "    pitch_interpolated = pitch.interpolate(method=\"linear\")\n",
    "    pitch_smoothed = savgol_filter(pitch_interpolated, window_length=5, polyorder=2)\n",
    "    return pitch_smoothed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract pitch from pitch file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_path_kj = \"../data/raw/Koti Janmani/Koti Janmani.pitch.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pitch_file(path: str):\n",
    "    \"\"\"\n",
    "    Load a pitch file from a given path.\n",
    "\n",
    "    :param path: Path to the pitch file.\n",
    "    :return: pitch_file, time, pitch, timestep\n",
    "    \"\"\"\n",
    "    pitch_file = pd.read_csv(path, sep=\"\\t\", header=None)\n",
    "    pitch_file.columns = [\"time\", \"pitch\"]\n",
    "\n",
    "    time = pitch_file[\"time\"].values\n",
    "    pitch = pitch_file[\"pitch\"].values\n",
    "    timestep = time[1] - time[0]\n",
    "\n",
    "    return pitch_file, time, pitch, timestep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_file_kj, time_kj, pitch_kj, timestep_kj = load_pitch_file(pitch_path_kj)\n",
    "\n",
    "# Replace non-positive values with NaN, interpolate and smooth\n",
    "pitch_kj_smoothed = interpolate_and_smooth_pitch(pitch_kj)\n",
    "\n",
    "# Convert pitch to cents (TODO: should we use the smoothed? why?)\n",
    "pitch_cents_kj = np.array([pitch_to_cents(p, ctonic_ref) for p in pitch_kj_smoothed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pitch_file_kj\n",
    "pitch_cents_kj[10000:10020]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOT WORKING YET (extracting pitch from audio file using Melodia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib.util\n",
    "if importlib.util.find_spec('compiam') is None:\n",
    "    ## Bear in mind this will only run in a jupyter notebook / Collab session\n",
    "    %pip install compiam\n",
    "\n",
    "import compiam\n",
    "#!git clone https://github.com/MTG/essentia.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install wheel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install essentia --use-pep517\n",
    "%pip install essentia --no-cache-dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import essentia\n",
    "# Extract pitch using Melodia\n",
    "import essentia\n",
    "#import essentia/src/algorithms/standard as es\n",
    "from compiam.melody.pitch_extraction import Melodia\n",
    "from compiam.melody.pitch_extraction import FTANetCarnatic\n",
    "# from compiam.melody.pitch_extraction import FTANetCarnatic\n",
    "\n",
    "\n",
    "melodia = Melodia()\n",
    "# ftanet = FTANetCarnatic()\n",
    "\n",
    "melodia_pitch_track = melodia.extract(audio_path)\n",
    "\n",
    "# Separate pitch and time\n",
    "pitch = melodia_pitch_track[:, 1]\n",
    "time = melodia_pitch_track[:, 0]\n",
    "\n",
    "timestep = time[1] - time[0]\n",
    "\n",
    "# Convert pitch to cents\n",
    "pitch_cents = np.array([pitch_to_cents(p, ctonic_ref) for p in pitch])\n",
    "\n",
    "\n",
    "#save melodia pitch track into csv file in same folder\n",
    "melodia_pitch_track_df = pd.DataFrame(melodia_pitch_track, columns=[\"time\", \"pitch\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#melodia_pitch_track_df.to_csv(\"../data/raw/Koti Janmani/Koti Janmani.melodia.pitch.txt\", sep=\"\\t\", index=False)\n",
    "\n",
    "#save to csv without creating a dataframe first row time second pitch\n",
    "np.savetxt(\"../data/raw/Koti Janmani/Koti Janmani.melodia.pitch.txt\", melodia_pitch_track, delimiter=\"\\t\")\n",
    "#np.savetxt(\"../data/raw/Vanajaksha Ninne Kori/Vanajaksha Ninne Kori.melodia.pitch.txt\", melodia_pitch_track, delimiter=\"\\t\")\n",
    "\n",
    "#melodia_pitch_track_df.to_csv(\"../data/raw/Vanajaksha Ninne Kori/Vanajaksha Ninne Kori.melodia.pitch.txt\", sep=\"\\t\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE EXAMPLE to extract some features from an annotation\n",
    "\n",
    "# Start, end points, and label of pattern from annotations\n",
    "s1 = 5.238\n",
    "s2 = 8.300\n",
    "label = 'mgmpmmgrg'\n",
    "\n",
    "# convert to number of sequence elements\n",
    "s1_ix = round(s1/timestep)\n",
    "s2_ix = round(s2/timestep)\n",
    "\n",
    "# Segment pitch curve to correspond only to that pattern\n",
    "samp_time = time[s1_ix:s2_ix]\n",
    "samp_pitch = pitch_cents[s1_ix:s2_ix]\n",
    "\n",
    "# Plot pattern\n",
    "plt.plot(samp_time, samp_pitch)\n",
    "plt.title(label)\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Frequency (Hz)')\n",
    "\n",
    "# Remove none values corresponding to silence\n",
    "samp_pitch_clean = [x for x in samp_pitch if x != None]\n",
    "\n",
    "# Extract features from cleaned cents sample...\n",
    "max(samp_pitch_clean)\n",
    "min(samp_pitch_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Time Domain Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from librosa.feature import rms\n",
    "from librosa.feature import zero_crossing_rate as zcr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_features_df = annotations_sancara.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 Amplitude Envelope ¿¿??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No se si serveix d'algo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 Root Mean Square Energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rms(audio: np.ndarray, sample_start: float, sample_end: float, sr: int) -> float:\n",
    "    sample = audio[round(sample_start * sr):round(sample_end * sr)]\n",
    "    return np.mean(rms(y=sample)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: a stands for annotation\n",
    "time_features_df['rmse'] = time_features_df.apply(\n",
    "    lambda a: compute_rms(audio_kj, a['start'], a['end'], sr_kj), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.3 Zero Crossing Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_zcr(audio: np.ndarray, sample_start: float, sample_end: float, sr: int) -> float:\n",
    "    sample = audio[round(sample_start * sr):round(sample_end * sr)]\n",
    "    return np.mean(zcr(y=sample)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_features_df['zcr'] = time_features_df.apply(\n",
    "    lambda a: compute_zcr(audio_kj, a['start'], a['end'], sr_kj), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time Domain Features DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Frequency Domain Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from librosa.feature import spectral_centroid as scentroid\n",
    "from librosa.feature import spectral_bandwidth as sbandwidth\n",
    "from librosa.feature import spectral_rolloff as srolloff\n",
    "from librosa.feature import mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_features_df = annotations_sancara.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 Band Energy Ratio (not necessary??)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Passar el codi de l'altre notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 Spectral Centroid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each frame of a magnitude spectrogram is normalized and treated as a distribution over frequency bins, from which the mean (centroid) is extracted per frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_scentroid(audio: np.ndarray, sample_start: float, sample_end: float, sr: int) -> float:\n",
    "    sample = audio[round(sample_start * sr):round(sample_end * sr)]\n",
    "    return np.mean(scentroid(y=sample, sr=sr)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_features_df['spectral_centroid'] = frequency_features_df.apply(\n",
    "    lambda a: compute_scentroid(audio_kj, a['start'], a['end'], sr_kj), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.3 Spectral Bandwidth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sbandwidth(audio: np.ndarray, sample_start: float, sample_end: float, sr: int) -> float:\n",
    "    sample = audio[round(sample_start * sr):round(sample_end * sr)]\n",
    "    return np.mean(sbandwidth(y=sample, sr=sr)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_features_df['spectral_bandwidth'] = frequency_features_df.apply(\n",
    "    lambda a: compute_sbandwidth(audio_kj, a['start'], a['end'], sr_kj), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.4 Spectral Rolloff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The roll-off frequency is defined for each frame as the center frequency for a spectrogram bin such that at least roll_percent (0.85 by default) of the energy of the spectrum in this frame is contained in this bin and the bins below. This can be used to, e.g., approximate the maximum (or minimum) frequency by setting roll_percent to a value close to 1 (or 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_srolloff(audio: np.ndarray, sample_start: float, sample_end: float, sr: int) -> float:\n",
    "    sample = audio[round(sample_start * sr):round(sample_end * sr)]\n",
    "    return np.mean(srolloff(y=sample, sr=sr)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_features_df['spectral_rolloff'] = frequency_features_df.apply(\n",
    "    lambda a: compute_srolloff(audio_kj, a['start'], a['end'], sr_kj), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.5 Mel Frequency Cepstral Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_df = annotations_sancara.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mfcc(audio: np.ndarray, sample_start: float, sample_end: float, sr: int) -> np.ndarray:\n",
    "    sample = audio[round(sample_start * sr):round(sample_end * sr)]\n",
    "    return np.mean(mfcc(y=sample, sr=sr, n_mfcc=13), axis=1)\n",
    "\n",
    "mfcc_cols = [f'mfcc_{i+1}' for i in range(13)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_df[mfcc_cols] = mfcc_df.apply(\n",
    "    lambda a: compute_mfcc(audio_kj, a['start'], a['end'], sr_kj), axis=1\n",
    ").apply(pd.Series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequency Domain Features DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#frequency_features_df\n",
    "#mfcc_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.4 Spectral Contrast ¿¿??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each frame of a spectrogram S is divided into sub-bands. For each sub-band, the energy contrast is estimated by comparing the mean energy in the top quantile (peak energy) to that of the bottom quantile (valley energy). High contrast values generally correspond to clear, narrow-band signals, while low contrast values correspond to broad-band noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Pitch Curve Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_features_df = annotations_sancara.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1 Mean pitch, Min/Max and Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Not sure if the min_pitch and max_pitch correspond to each annotation\n",
    "\n",
    "def get_mean_min_max_pitch(cents: np.ndarray, tstep: float, sample_start: float, sample_end: float):\n",
    "    #sample_time = time[round(sample_start/tstep):round(sample_end/tstep)]\n",
    "    sample_cents = cents[round(sample_start/tstep):round(sample_end/tstep)]\n",
    "    \"\"\" sample_cents_clean = [x for x in sample_cents if x is not None]\n",
    "    if not sample_cents_clean:\n",
    "        return None \"\"\"\n",
    "    return np.mean(sample_cents), min(sample_cents), max(sample_cents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_features_df[['mean_pitch', 'min_pitch', 'max_pitch']] = pitch_features_df.apply(\n",
    "    lambda a: get_mean_min_max_pitch(pitch_cents_kj, timestep_kj, a['start'], a['end']), axis=1\n",
    ").apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Range\n",
    "pitch_features_df['pitch_range'] = pitch_features_df['max_pitch'] - pitch_features_df['min_pitch']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2 Number of Change Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import find_peaks\n",
    "\n",
    "def compute_number_of_change_points(cents: np.ndarray, tstep: float, sample_start: float, sample_end: float) -> int:\n",
    "    #sample_time = time[round(sample_start/tstep):round(sample_end/tstep)]\n",
    "    sample_cents = cents[round(sample_start/tstep):round(sample_end/tstep)]\n",
    "\n",
    "    peaks, _ = find_peaks(sample_cents)\n",
    "    valleys, _ = find_peaks(-sample_cents)\n",
    "\n",
    "    num_change_points = len(peaks) + len(valleys)\n",
    "    return num_change_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_features_df['num_change_points'] = pitch_features_df.apply(\n",
    "    lambda a: compute_number_of_change_points(pitch_cents_kj, timestep_kj, a['start'], a['end']), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pitch Curve Features DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Create DataFrame with the Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = [\"index\", \"level\", \"start\", \"end\", \"duration\",\"label\"]\n",
    "features_df = pd.concat([annotations_sancara, \n",
    "                        time_features_df.drop(columns=cols_to_drop),\n",
    "                        frequency_features_df.drop(columns=cols_to_drop),\n",
    "                        mfcc_df.drop(columns=cols_to_drop),\n",
    "                        pitch_features_df.drop(columns=cols_to_drop)],\n",
    "axis=1)\n",
    "\n",
    "# TODO: Normalize the data\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = annotations_kj.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['label'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Get Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Falten BER.\n",
    "features = ['rmse', 'zcr', \n",
    "            'spectral_centroid', 'spectral_bandwidth', 'spectral_rolloff',\n",
    "            'mfcc_1', 'mfcc_2', 'mfcc_3', 'mfcc_4', 'mfcc_5', 'mfcc_6', 'mfcc_7', 'mfcc_8', 'mfcc_9', 'mfcc_10', 'mfcc_11', 'mfcc_12', 'mfcc_13', \n",
    "            'mean_pitch', 'min_pitch', 'max_pitch', 'pitch_range', 'num_change_points']\n",
    "target = ['label'] # ¿?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[features].values\n",
    "y = df[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "len(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Train a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
