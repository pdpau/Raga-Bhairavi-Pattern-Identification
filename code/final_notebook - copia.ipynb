{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREGUNTES PER AL THOMAS\n",
    "# 2. How to get Melodia working?\n",
    "\n",
    "\n",
    "# FIND 2 PATTERNS AND TRAIN A MODEL TO PREDICT THOSE 2 PATTERNS\n",
    "\n",
    "\n",
    "# Normalizing the cents\n",
    "\n",
    "# Raga Ritigowla\n",
    "\n",
    "\n",
    "# VISUALIZATION\n",
    "# MatPlotLib to visualize the patterns (it's the easiest)\n",
    "# Plotly dash (more complex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install gdown\n",
    "# %pip install configobj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import compiam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_kj_path = \"../data/raw/annotations_koti_janmani.txt\"\n",
    "annotations_vnk_path = \"../data/raw/annotations_vanajaksha_ninni_kore.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_seconds(t):\n",
    "    return (t.hour * 60 * 60) + (t.minute * 60) + t.second + (t.microsecond / 1000000)\n",
    "\n",
    "def load_annotations_file(path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load annotations from a file.\n",
    "\n",
    "    :param path: Path to the file containing the annotations.\n",
    "    :return: A pandas DataFrame containing the annotations.\n",
    "    \"\"\"\n",
    "    # Read the annotations file\n",
    "    annotations = pd.read_csv(path, sep='\\t', header=None)\n",
    "\n",
    "    # Add column names\n",
    "    annotations.columns = [\"level\", \"\", \"start\", \"end\", \"duration\", \"label\"]\n",
    "    del annotations[\"\"]\n",
    "\n",
    "    # Convert to seconds\n",
    "    annotations[\"start\"] = pd.to_datetime(annotations[\"start\"])\n",
    "    annotations[\"end\"] = pd.to_datetime(annotations[\"end\"])\n",
    "    annotations[\"start\"] = annotations[\"start\"].apply(to_seconds)\n",
    "    annotations[\"end\"] = annotations[\"end\"].apply(to_seconds)\n",
    "\n",
    "    annotations.reset_index(inplace=True)\n",
    "\n",
    "    return annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_kj = load_annotations_file(annotations_kj_path)\n",
    "annotations_vnk = load_annotations_file(annotations_vnk_path)\n",
    "\n",
    "#annotations_vnk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_kj_usancara = annotations_kj[annotations_kj[\"level\"] == \"underlying_sancara\"]\n",
    "annotations_vnk_usancara = annotations_vnk[annotations_vnk[\"level\"] == \"root_sancara\"]\n",
    "\n",
    "#annotations_vnk_usancara"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_kj_path = \"../data/raw/Koti Janmani/Koti Janmani.multitrack-vocal.mp3\"\n",
    "audio_vnk_path = \"../data/raw/Vanajaksha Ninne Kori/Vanajaksha Ninne Kori_vocal.mp3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio_file(path: str, sampling_rate: int) -> tuple:\n",
    "    audio_time_series, sr = librosa.load(path, sr=sampling_rate)\n",
    "    return audio_time_series, sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_kj, sr_kj = load_audio_file(audio_kj_path, 44100)\n",
    "audio_vnk, sr_vnk = load_audio_file(audio_vnk_path, 44100)\n",
    "\n",
    "Audio(data=audio_vnk, rate=sr_vnk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Extract pitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passar la ref a una constant (per fer el canvi de Hz a cents)\n",
    "tonic_path_kj = \"../data/raw/Koti Janmani/Koti Janmani.ctonic.txt\"\n",
    "tonic_path_vnk = \"../data/raw/Vanajaksha Ninne Kori/Vanajaksha Ninne Kori.ctonic.txt\"\n",
    "\n",
    "with open(tonic_path_kj, \"r\") as f:\n",
    "    ctonic_ref_kj = float(f.readline().strip())\n",
    "\n",
    "with open(tonic_path_vnk, \"r\") as f:\n",
    "    ctonic_ref_vnk = float(f.readline().strip())\n",
    "\n",
    "ctonic_ref_vnk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import savgol_filter\n",
    "\n",
    "def pitch_to_cents(pitch: float, ref: float):\n",
    "    if pitch == 0:\n",
    "        return None\n",
    "    else:\n",
    "        return 1200 * math.log(pitch/ref, 2)\n",
    "\n",
    "def interpolate_and_smooth_pitch(pitch):\n",
    "    pitch = pd.Series(pitch)\n",
    "    pitch[pitch <= 0] = np.nan\n",
    "    pitch_interpolated = pitch.interpolate(method=\"linear\")\n",
    "    pitch_smoothed = savgol_filter(pitch_interpolated, window_length=5, polyorder=2)\n",
    "    return pitch_smoothed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract pitch from pitch file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_path_kj = \"../data/raw/Koti Janmani/Koti Janmani.melodia.pitch.txt\"\n",
    "pitch_path_vnk = \"../data/raw/Vanajaksha Ninne Kori/Vanajaksha Ninne Kori.melodia.pitch.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pitch_file(path: str):\n",
    "    \"\"\"\n",
    "    Load a pitch file from a given path.\n",
    "\n",
    "    :param path: Path to the pitch file.\n",
    "    :return: pitch_file, time, pitch, timestep\n",
    "    \"\"\"\n",
    "    pitch_file = pd.read_csv(path, sep=\"\\t\", header=None)\n",
    "    pitch_file.columns = [\"time\", \"pitch\"]\n",
    "\n",
    "    time = pitch_file[\"time\"].values\n",
    "    pitch = pitch_file[\"pitch\"].values\n",
    "    timestep = time[1] - time[0]\n",
    "\n",
    "    return pitch_file, time, pitch, timestep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_file_kj, time_kj, pitch_kj, timestep_kj = load_pitch_file(pitch_path_kj)\n",
    "pitch_file_vnk, time_vnk, pitch_vnk, timestep_vnk = load_pitch_file(pitch_path_vnk)\n",
    "\n",
    "# Replace non-positive values with NaN, interpolate and smooth\n",
    "pitch_kj_smoothed = interpolate_and_smooth_pitch(pitch_kj)\n",
    "pitch_vnk_smoothed = interpolate_and_smooth_pitch(pitch_vnk)\n",
    "\n",
    "# Convert pitch to cents\n",
    "pitch_cents_kj = np.array([pitch_to_cents(p, ctonic_ref_kj) for p in pitch_kj_smoothed])\n",
    "pitch_cents_vnk = np.array([pitch_to_cents(p, ctonic_ref_vnk) for p in pitch_vnk_smoothed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pitch_cents_kj[10000:10020]\n",
    "pitch_cents_vnk[10000:10020]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pitch was extracted using melodia and saved into the files: \"Koti Janmani.melodia.pitch.txt\" , \"Vanajaksha Ninne Kori.melodia.pitch.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Time Domain Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from librosa.feature import rms\n",
    "from librosa.feature import zero_crossing_rate as zcr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_features_kj_df = annotations_kj_usancara.copy()\n",
    "time_features_vnk_df = annotations_vnk_usancara.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 Amplitude Envelope ¿¿??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No se si serveix d'algo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 Root Mean Square Energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rms(audio: np.ndarray, sample_start: float, sample_end: float, sr: int) -> float:\n",
    "    sample = audio[round(sample_start * sr):round(sample_end * sr)]\n",
    "    return np.mean(rms(y=sample)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: a stands for annotation\n",
    "time_features_kj_df['rmse'] = time_features_kj_df.apply(\n",
    "    lambda a: compute_rms(audio_kj, a['start'], a['end'], sr_kj), axis=1\n",
    ")\n",
    "time_features_vnk_df['rmse'] = time_features_vnk_df.apply(\n",
    "    lambda a: compute_rms(audio_vnk, a['start'], a['end'], sr_vnk), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.3 Zero Crossing Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_zcr(audio: np.ndarray, sample_start: float, sample_end: float, sr: int) -> float:\n",
    "    sample = audio[round(sample_start * sr):round(sample_end * sr)]\n",
    "    return np.mean(zcr(y=sample)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_features_kj_df['zcr'] = time_features_kj_df.apply(\n",
    "    lambda a: compute_zcr(audio_kj, a['start'], a['end'], sr_kj), axis=1\n",
    ")\n",
    "time_features_vnk_df['zcr'] = time_features_vnk_df.apply(\n",
    "    lambda a: compute_zcr(audio_vnk, a['start'], a['end'], sr_vnk), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time Domain Features DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_features_kj_df\n",
    "# time_features_vnk_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Frequency Domain Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from librosa.feature import spectral_centroid as scentroid\n",
    "from librosa.feature import spectral_bandwidth as sbandwidth\n",
    "from librosa.feature import spectral_rolloff as srolloff\n",
    "from librosa.feature import mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_features_kj_df = annotations_kj_usancara.copy()\n",
    "frequency_features_vnk_df = annotations_vnk_usancara.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 Band Energy Ratio (not necessary??)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Passar el codi de l'altre notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 Spectral Centroid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each frame of a magnitude spectrogram is normalized and treated as a distribution over frequency bins, from which the mean (centroid) is extracted per frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_scentroid(audio: np.ndarray, sample_start: float, sample_end: float, sr: int) -> float:\n",
    "    sample = audio[round(sample_start * sr):round(sample_end * sr)]\n",
    "    return np.mean(scentroid(y=sample, sr=sr)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_features_kj_df['spectral_centroid'] = frequency_features_kj_df.apply(\n",
    "    lambda a: compute_scentroid(audio_kj, a['start'], a['end'], sr_kj), axis=1\n",
    ")\n",
    "frequency_features_vnk_df['spectral_centroid'] = frequency_features_vnk_df.apply(\n",
    "    lambda a: compute_scentroid(audio_vnk, a['start'], a['end'], sr_vnk), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.3 Spectral Bandwidth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sbandwidth(audio: np.ndarray, sample_start: float, sample_end: float, sr: int) -> float:\n",
    "    sample = audio[round(sample_start * sr):round(sample_end * sr)]\n",
    "    return np.mean(sbandwidth(y=sample, sr=sr)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_features_kj_df['spectral_bandwidth'] = frequency_features_kj_df.apply(\n",
    "    lambda a: compute_sbandwidth(audio_kj, a['start'], a['end'], sr_kj), axis=1\n",
    ")\n",
    "frequency_features_vnk_df['spectral_bandwidth'] = frequency_features_vnk_df.apply(\n",
    "    lambda a: compute_sbandwidth(audio_vnk, a['start'], a['end'], sr_vnk), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.4 Spectral Rolloff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The roll-off frequency is defined for each frame as the center frequency for a spectrogram bin such that at least roll_percent (0.85 by default) of the energy of the spectrum in this frame is contained in this bin and the bins below. This can be used to, e.g., approximate the maximum (or minimum) frequency by setting roll_percent to a value close to 1 (or 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_srolloff(audio: np.ndarray, sample_start: float, sample_end: float, sr: int) -> float:\n",
    "    sample = audio[round(sample_start * sr):round(sample_end * sr)]\n",
    "    return np.mean(srolloff(y=sample, sr=sr)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_features_kj_df['spectral_rolloff'] = frequency_features_kj_df.apply(\n",
    "    lambda a: compute_srolloff(audio_kj, a['start'], a['end'], sr_kj), axis=1\n",
    ")\n",
    "frequency_features_vnk_df['spectral_rolloff'] = frequency_features_vnk_df.apply(\n",
    "    lambda a: compute_srolloff(audio_vnk, a['start'], a['end'], sr_vnk), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.5 Mel Frequency Cepstral Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_kj_df = annotations_kj_usancara.copy()\n",
    "mfcc_vnk_df = annotations_vnk_usancara.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mfcc(audio: np.ndarray, sample_start: float, sample_end: float, sr: int) -> np.ndarray:\n",
    "    sample = audio[round(sample_start * sr):round(sample_end * sr)]\n",
    "    return np.mean(mfcc(y=sample, sr=sr, n_mfcc=13), axis=1)\n",
    "\n",
    "mfcc_cols = [f'mfcc_{i+1}' for i in range(13)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_kj_df[mfcc_cols] = mfcc_kj_df.apply(\n",
    "    lambda a: compute_mfcc(audio_kj, a['start'], a['end'], sr_kj), axis=1\n",
    ").apply(pd.Series)\n",
    "mfcc_vnk_df[mfcc_cols] = mfcc_vnk_df.apply(\n",
    "    lambda a: compute_mfcc(audio_vnk, a['start'], a['end'], sr_vnk), axis=1\n",
    ").apply(pd.Series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequency Domain Features DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#frequency_features_kj_df\n",
    "#frequency_features_vnk_df\n",
    "#mfcc_kj_df\n",
    "#mfcc_vnk_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.4 Spectral Contrast ¿¿??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each frame of a spectrogram S is divided into sub-bands. For each sub-band, the energy contrast is estimated by comparing the mean energy in the top quantile (peak energy) to that of the bottom quantile (valley energy). High contrast values generally correspond to clear, narrow-band signals, while low contrast values correspond to broad-band noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Pitch Curve Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_features_kj_df = annotations_kj_usancara.copy()\n",
    "pitch_features_vnk_df = annotations_vnk_usancara.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1 Mean pitch, Min/Max and Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Not sure if the min_pitch and max_pitch correspond to each annotation\n",
    "\n",
    "def get_mean_min_max_pitch(cents: np.ndarray, tstep: float, sample_start: float, sample_end: float):\n",
    "    #sample_time = time[round(sample_start/tstep):round(sample_end/tstep)]\n",
    "    sample_cents = cents[round(sample_start/tstep):round(sample_end/tstep)]\n",
    "    \"\"\" sample_cents_clean = [x for x in sample_cents if x is not None]\n",
    "    if not sample_cents_clean:\n",
    "        return None \"\"\"\n",
    "    return np.mean(sample_cents), min(sample_cents), max(sample_cents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_features_kj_df[['mean_pitch', 'min_pitch', 'max_pitch']] = pitch_features_kj_df.apply(\n",
    "    lambda a: get_mean_min_max_pitch(pitch_cents_kj, timestep_kj, a['start'], a['end']), axis=1\n",
    ").apply(pd.Series)\n",
    "pitch_features_vnk_df[['mean_pitch', 'min_pitch', 'max_pitch']] = pitch_features_vnk_df.apply(\n",
    "    lambda a: get_mean_min_max_pitch(pitch_cents_vnk, timestep_vnk, a['start'], a['end']), axis=1\n",
    ").apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Range\n",
    "pitch_features_kj_df['pitch_range'] = pitch_features_kj_df['max_pitch'] - pitch_features_kj_df['min_pitch']\n",
    "pitch_features_vnk_df['pitch_range'] = pitch_features_vnk_df['max_pitch'] - pitch_features_vnk_df['min_pitch']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2 Number of Change Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use PROMINENCE no get only significant change points (> 70 cents is significant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import find_peaks\n",
    "\n",
    "def compute_number_of_change_points(cents: np.ndarray, tstep: float, sample_start: float, sample_end: float) -> int:\n",
    "    #sample_time = time[round(sample_start/tstep):round(sample_end/tstep)]\n",
    "    sample_cents = cents[round(sample_start/tstep):round(sample_end/tstep)]\n",
    "\n",
    "    peaks, _ = find_peaks(sample_cents, prominence=70)\n",
    "    valleys, _ = find_peaks(-sample_cents, prominence=70)\n",
    "\n",
    "    num_change_points = len(peaks) + len(valleys)\n",
    "    return num_change_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_features_kj_df['num_change_points'] = pitch_features_kj_df.apply(\n",
    "    lambda a: compute_number_of_change_points(pitch_cents_kj, timestep_kj, a['start'], a['end']), axis=1\n",
    ")\n",
    "pitch_features_vnk_df['num_change_points'] = pitch_features_vnk_df.apply(\n",
    "    lambda a: compute_number_of_change_points(pitch_cents_vnk, timestep_vnk, a['start'], a['end']), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.3 Number of Change Points per second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pitch Curve Features DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_features_kj_df\n",
    "# pitch_features_vnk_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Create DataFrame with the Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = [\"index\", \"level\", \"start\", \"end\", \"duration\", \"label\"]\n",
    "features_kj_df = pd.concat([annotations_kj_usancara, \n",
    "                        time_features_kj_df.drop(columns=cols_to_drop),\n",
    "                        frequency_features_kj_df.drop(columns=cols_to_drop),\n",
    "                        mfcc_kj_df.drop(columns=cols_to_drop),\n",
    "                        pitch_features_kj_df.drop(columns=cols_to_drop)],\n",
    "axis=1)\n",
    "features_vnk_df = pd.concat([annotations_vnk_usancara,\n",
    "                        time_features_vnk_df.drop(columns=cols_to_drop),\n",
    "                        frequency_features_vnk_df.drop(columns=cols_to_drop),\n",
    "                        mfcc_vnk_df.drop(columns=cols_to_drop),\n",
    "                        pitch_features_vnk_df.drop(columns=cols_to_drop)],\n",
    "axis=1)\n",
    "\n",
    "# TODO: Normalize the data\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evaluate if each feature is significant or not\n",
    "\"\"\" df_ns = df[df['is_nns']==1]\n",
    "df_no_ns = df[df['is_nns']!=1]\n",
    "print(np.mean(df_ns[feature]))\n",
    "print(np.mean(df_no_ns[feature])) \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_df = features_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patterns to use:\n",
    "# trial_df['label'].value_counts()\n",
    "# 1. 'sssnnpn'\n",
    "# 2. 'mgmpmggrs'\n",
    "# 3. 'gmn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Get Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Falten BER.\n",
    "features = ['rmse', 'zcr', \n",
    "            'spectral_centroid', 'spectral_bandwidth', 'spectral_rolloff',\n",
    "            'mfcc_1', 'mfcc_2', 'mfcc_3', 'mfcc_4', 'mfcc_5', 'mfcc_6', 'mfcc_7', 'mfcc_8', 'mfcc_9', 'mfcc_10', 'mfcc_11', 'mfcc_12', 'mfcc_13', \n",
    "            'mean_pitch', 'min_pitch', 'max_pitch', 'pitch_range', 'num_change_points']\n",
    "target1 = ['is_{pattern}']\n",
    "target2 = ['is_{pattern}']\n",
    "target3 = ['is_{pattern}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[features].values\n",
    "y = df[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "len(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Train a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'n_estimators':[10,50,100],\n",
    "    'learning_rate':[0.001,0.01,0.1,1],\n",
    "    'max_depth':[2, 4, 8],\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(clf, param_grid=params, scoring='f1', cv=2)\n",
    "gs.fit(X_train, y_train)\n",
    "best_clf = gs.best_estimator_\n",
    "pd.DataFrame(gs.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clf.predict(X_test)\n",
    "y_pred = best_clf.predict(X_test)\n",
    "f1_score(y_pred, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
