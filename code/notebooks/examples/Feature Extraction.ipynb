{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "premier-merchandise",
   "metadata": {},
   "source": [
    "# 2. Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pretty-award",
   "metadata": {},
   "source": [
    "In this notebook we will extract various audio features for a sample of audio. We will focus on the time domain features of:\n",
    "\n",
    "- Amplitude Envelope \n",
    "- Root-Mean-Squared Energy\n",
    "- Zero Crossing Rate\n",
    "\n",
    "The frequency domain features of:\n",
    "\n",
    "- Band Energy Ratio\n",
    "- Spectral Centroid\n",
    "- Bandwidth\n",
    "- Mel Frequency Cepstral Coefficients\n",
    "\n",
    "And the pitch curve features of:\n",
    "- Minimum Pitch\n",
    "- Maximum Pitch\n",
    "- Pitch Range\n",
    "- Number of Change Points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "terminal-leonard",
   "metadata": {},
   "source": [
    "## 2.1 Load Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amazing-fraction",
   "metadata": {},
   "source": [
    "Before beginning let's load a single performance audio. If computing power is a limitation you might want to consider loading the entire audio and taking a sample to work with for this notebook.\n",
    "\n",
    "Hint: `librosa.load` might be useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "neural-reaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = '<insert audio path here>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "nearby-beach",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load one individual sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "therapeutic-delhi",
   "metadata": {},
   "source": [
    "Are you able to listen to this audio and plot the waveform.\n",
    "\n",
    "**Hint**: You should find that the `Ipythoon.display.Audio` useful for playing audio inline in a Jupyter notebook.\n",
    "\n",
    "**Hint**: Using the `matplotlib` library you can plot on two dimensions as so:\n",
    "\n",
    "```\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(x, y)\n",
    "```\n",
    "More information on enhancing these plots (e.g. with titles, axis labels and gridlines) can be found [here](https://matplotlib.org/stable/gallery/lines_bars_and_markers/simple_plot.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "rough-morning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listen to audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "traditional-estonia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot waveform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cardiovascular-drunk",
   "metadata": {},
   "source": [
    "## 2.1 Time Domain Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strong-central",
   "metadata": {},
   "source": [
    "Here we will extract the time domain features of:\n",
    "\n",
    "- Amplitude Envelope \n",
    "- Root-Mean-Squared Energy\n",
    "- Zero Crossing Rate\n",
    "\n",
    "We will work with the *time domain* representation of your audio (i.e. the amplitude values loaded by your loader)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disabled-malaysia",
   "metadata": {},
   "source": [
    "### 2.1.1 Amplitude Envelope"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hybrid-faculty",
   "metadata": {},
   "source": [
    "The amplitude is computed by splitting the  audio into frames and taking the maximum amplitude value for each frame..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuffed-cornwall",
   "metadata": {},
   "source": [
    "![title](images/amplitude_envelope.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divine-auditor",
   "metadata": {},
   "source": [
    "Try and split your audio into frames of length `w`. \n",
    "\n",
    "**Hint**: `numpy` indexing you to take windows of size `w` from an array using `np.array_split(array, w)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "synthetic-executive",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split audio array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "governing-sunglasses",
   "metadata": {},
   "source": [
    "Take the maximum value for each window using `np.max()`.\n",
    "\n",
    "**Hint** A list comprehension may be useful here: `[<f(x)> for x in <iterable>]` where `<iterable>` is some iterable object and `<f(x)>` is some functon to apply to each  element of that iterable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "statewide-period",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get amplitude envelope by taking the max of the values of the split array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advance-unemployment",
   "metadata": {},
   "source": [
    "Can you plot this envelope using `matplotlib.pyplot`. How does it compare with the original signal?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fiscal-chicken",
   "metadata": {},
   "source": [
    "### 2.1.2 Root Mean Square Energy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "buried-winter",
   "metadata": {},
   "source": [
    "The RMS energy is computed using"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superior-prototype",
   "metadata": {},
   "source": [
    "![title](images/rms_energy.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "successful-recycling",
   "metadata": {},
   "source": [
    "The `librosa` libray has an implementation at `librosa.feature.rms`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turned-treasurer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import librosa rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "billion-independence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extact rms value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "religious-angola",
   "metadata": {},
   "source": [
    "### 2.1.3 Zero Crossing Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composed-stadium",
   "metadata": {},
   "source": [
    "The zero crossing rate is the number of times the signal crosses the x axis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civil-iceland",
   "metadata": {},
   "source": [
    "![title](images/zero_crossing_graph.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "studied-cargo",
   "metadata": {},
   "source": [
    "It is computed with the following equation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "christian-nomination",
   "metadata": {},
   "source": [
    "![title](images/zero_crossing_eq.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signal-tokyo",
   "metadata": {},
   "source": [
    "The `librosa` library provides an implementaton at `librosa.feature.zero_crossing_rate`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "embedded-screening",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import librosa zero_crossing_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinguished-sixth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute ZCR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comic-pulse",
   "metadata": {},
   "source": [
    "## 2.2 Frequency Domain Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quick-shirt",
   "metadata": {},
   "source": [
    "Here we will extract the frequency domain features of:\n",
    "\n",
    "- Band Energy Ratio\n",
    "- Spectral Centroid\n",
    "- Bandwidth\n",
    "- Mel Frequency Cepstral Coefficients\n",
    "\n",
    "We will work with the **frequency domain** representation of your audio (i.e. the frequency magnitude extracted from the fourier transform of your time domain signal).\n",
    "\n",
    "Almost all implementations of these feature extractors will compute the frequency domain spectrum for you."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adequate-argentina",
   "metadata": {},
   "source": [
    "### 2.2.1 Band Energy Ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alert-doctrine",
   "metadata": {},
   "source": [
    "Band energy ratio is the ratio of energy between lower and higher frequency bands divided by some threshold, `F`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rotary-march",
   "metadata": {},
   "source": [
    "![title](images/bre_spec.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "responsible-tattoo",
   "metadata": {},
   "source": [
    "![title](images/bre_eq.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minus-hebrew",
   "metadata": {},
   "source": [
    "The `essentia` library provides an implementation for computing the BER at `essentia.standard.EnergyBandRatio`. Import it and extract for your signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vulnerable-fisher",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import essentia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-library",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute BER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exact-circle",
   "metadata": {},
   "source": [
    "### 2.2.2 Spectral Centroid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disabled-pottery",
   "metadata": {},
   "source": [
    "The spectral centroid is a weighted mean of energy across all frequency bands. It is computed as:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rubber-tracy",
   "metadata": {},
   "source": [
    "![title](images/spec_cent.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detected-europe",
   "metadata": {},
   "source": [
    "The `librosa` libary provides an implementation at `librosa.feature.spectral_centroid`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vietnamese-picture",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import librosa implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "essential-woman",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute centroid for your signal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equivalent-ridge",
   "metadata": {},
   "source": [
    "### 2.2.3 Bandwidth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forced-inquiry",
   "metadata": {},
   "source": [
    "The bandwidth captures the variance around spectral centroid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expired-stamp",
   "metadata": {},
   "source": [
    "![title](images/bandwidth.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virtual-horizontal",
   "metadata": {},
   "source": [
    "The `librosa` libary provides an implementation at `librosa.feature.spectral_bandwidth`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressed-juvenile",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import librosa implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biblical-startup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute bandwidth for your signal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authentic-senior",
   "metadata": {},
   "source": [
    "### 2.2.4 Mel Frequency Cepstral Coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inclusive-present",
   "metadata": {},
   "source": [
    "MFCC maps frequency magnitudes to the more perceptually relevant Mel frequencies. The mapping between frequency and Mel frequency is as follows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incredible-former",
   "metadata": {},
   "source": [
    "![title](images/mel_freq.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suited-faculty",
   "metadata": {},
   "source": [
    "This mapping is not a simple conversion. More information on exactly how this is achieved can be found [here](https://www.youtube.com/watch?v=9GHCiiDLHQ4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "future-fusion",
   "metadata": {},
   "source": [
    "The `librosa` libary provides an implementation at `librosa.feature.mfcc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "national-monitor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import librosa implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "challenging-mailman",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute MFCC coefficients for your signal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018e1def",
   "metadata": {},
   "source": [
    "## 2.3 Pitch Curve Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb6a691",
   "metadata": {},
   "source": [
    "Here we will extract the pitch curve features of:\n",
    "\n",
    "- Max Pitch\n",
    "- Min Pitch\n",
    "- Pitch Range\n",
    "- Number of Change Points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd86a8e",
   "metadata": {},
   "source": [
    "### 2.3.1 Load or Extract Pitch Track"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6878d65c",
   "metadata": {},
   "source": [
    "Some pitch features are best extracted from the time series of the predominant vocal pitch. If you already have the pitch curve extracted you should load it to a `numpy.array` of pitch and time values... `[(pitch, time),..]`\n",
    "\n",
    "Hint: You can load csv or tsv using `pandas.read_csv`\n",
    "\n",
    "Hint: To extract values to a numpy array from a pandas dataframe (`df`) column you can use `df['colname'].values`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdfa7dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pitch curve to pandas dataframe or numpy array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de77b7bb",
   "metadata": {},
   "source": [
    "Or alternatively extract the pitch curve using an existing implementation\n",
    "\n",
    "Hint: the `compiam` library has two pitch extractors implemented, `melodia` and `ftanet`. Each takes as an input the path (`vocal_path`) to the audio for which you want to extract the predominant pitch curve.\n",
    "\n",
    "```\n",
    "from compiam.melody.pitch_extraction import FTANetCarnatic\n",
    "from compiam.melody.pitch_extraction import Melodia\n",
    "\n",
    "melodia = Melodia() # initialise model\n",
    "ftanet = FTANetCarnatic() # initialise model\n",
    "\n",
    "melodia_pitch_track = melodia.extract(vocal_path)\n",
    "\n",
    "# melodia\n",
    "pitch = melodia_pitch_track[:,1]\n",
    "time = melodia_pitch_track[:,0]\n",
    "```\n",
    "\n",
    "Hint: Are you using the vocal stem or the mixed track? Have you applied source separation? Make sure to listen to the audio beforehand to ensure the quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6494f05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract pitch curve from path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0532ce5",
   "metadata": {},
   "source": [
    "### 2.3.2 Plot Pitch Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8a5be9",
   "metadata": {},
   "source": [
    "Are you able to plot a portion of this pitch curve?... frequency against time\n",
    "\n",
    "**Hint**: As above, `maplotlib.pyplot` will be useful here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebc2f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot portion of pitch curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7c3bdd",
   "metadata": {},
   "source": [
    "### 2.3.3 Pre-process Pitch Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8485e664",
   "metadata": {},
   "source": [
    "How does the pitch curve look. Do you need to apply some processing?\n",
    "\n",
    "**Hint**: You may look at `scipy.signal.savgol_filter` for smoothing\n",
    "\n",
    "**Hint**: To convert a frequency to cents above some reference point you can use the equation: `1200*log(f/ref, 2)` where `f` is the frequency and `ref` is the reference frequency, usually the performer tonic\n",
    "\n",
    "**Hint**: Are there any small erroneous gaps in the pitch curve? Perhaps listening to the audio might serve as a useful guide. If necessary you might want to interpolate these small gaps. `pd.Series.interpolate` has the ability to interpolate nan values, you must first replace the points in the curve that you want to interpolate with nan values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f296c72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff46bf6",
   "metadata": {},
   "source": [
    "### 2.3.4 Min/max Pitch and Range"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26787c15",
   "metadata": {},
   "source": [
    "With the pitch curve clean and smoothed, it should be relatively simple to identify max pitch, min pitch and pitch range.\n",
    "\n",
    "**Hint**: `numpy.min()` and `numpy.max()` may be useful here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47491e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract minimum pitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f304ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract maximum pitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7ff8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute pitch range"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba59912c",
   "metadata": {},
   "source": [
    "### 2.3.4 Number of Change Points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21dbb886",
   "metadata": {},
   "source": [
    "Identify change points (points of zero derivative) is slightly more complicated. We are interested in points at which the pitch curve changes direction. \n",
    "\n",
    "**Hint**: `scipy.signal.find_peaks()` should be sueful here, be sure to read the documentation, the most important parameter will be `prominence`\n",
    "\n",
    "**Hint**: `scipy.signal.find_peaks()` only identifies peaks in the pitch curve, but what about troughs? Flipping the curve in the y-direction before passing it to the function will convert peaks to troughs\n",
    "\n",
    "**Hint**: The following link contains a visual guide to `find_peaks()` parameters - https://stackoverflow.com/questions/1713335/peak-finding-algorithm-for-python-scipy\n",
    "\n",
    "**Hint**: Peaks or troughs with a topographic prominence (see `find_peaks` documentation) of below around 70 cents could reasonably be discounted as vibrato rather than ornamentation owing to musically meaningful gamaka\n",
    "\n",
    "**Hint**: Be sure to plot your curve with the idenified peaks to ensure it is working correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e0a1dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify number of change points in pitch curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "czech-apple",
   "metadata": {},
   "source": [
    "## 2.4 Extracting features across the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "settled-majority",
   "metadata": {},
   "source": [
    "Now that you are able to extract features for one individual sample. Let's apply this to the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "nuclear-objective",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of filepaths to process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "czech-league",
   "metadata": {},
   "source": [
    "For each filepath, load the audio sample and apply the feature extractors defined above. Make sure to store these features in a dataframe with columns=\\[`index`,`feature1`,`feature2`,`feature3`,...\\].\n",
    "\n",
    "**Hint**: `pandas.DataFrame` initialises a new dataframe\n",
    "\n",
    "**Hint**: `df.append` appends new rows to a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efficient-reservoir",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through df\n",
    "# extract features\n",
    "# store in new features dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "congressional-tracy",
   "metadata": {},
   "source": [
    "Store this features dataframe alongside the original dataset\n",
    "\n",
    "**Hint**: `df.to_csv` writes a dataframe to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "needed-worst",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write dataframe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
